{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3e992a",
   "metadata": {},
   "source": [
    "(i_mod_sc)=\n",
    "# {{ name_mod_sc }}\n",
    "\n",
    "**{{ term_mod_sc }}**: {{ term_def_mod_sc }}\n",
    "\n",
    "::::::{dropdown} Assumptions, Pros, Cons\n",
    ":::::{grid}\n",
    "\n",
    "::::{grid-item-card} Assumptions\n",
    "- {{ mod_sc_assump_01 }}\n",
    "- {{ mod_sc_assump_02 }}\n",
    "- {{ mod_sc_assump_03 }}\n",
    "- {{ mod_sc_assump_04 }}\n",
    "- {{ mod_sc_assump_05 }}\n",
    "- {{ mod_sc_assump_06 }}\n",
    "::::\n",
    "::::{grid-item-card} Pros\n",
    "- {{ mod_sc_pro_01 }}\n",
    "::::\n",
    "::::{grid-item-card} Cons\n",
    "- {{ mod_sc_con_01 }}\n",
    "- {{ mod_sc_con_02 }}\n",
    "- {{ mod_sc_con_03 }}\n",
    "- {{ mod_sc_con_04 }}\n",
    "- {{ mod_sc_con_05 }}\n",
    "- {{ mod_sc_con_06 }}\n",
    "- {{ mod_sc_con_07 }}\n",
    "::::\n",
    ":::::\n",
    "::::::\n",
    "\n",
    ":::::::{tab-set}\n",
    "\n",
    "::::::{tab-item} Overview\n",
    "This section will be available soon! In the meantime, check out the information in the other tabs!\n",
    "\n",
    "```{figure} ../03_images/03_image_files/00_coming_soon.png\n",
    ":width: 300px\n",
    ":align: center\n",
    "```\n",
    "::::::\n",
    "\n",
    "::::::{tab-item} In-depth\n",
    ":::{note}\n",
    "**This content was adapted from**: The Density Handbook, \"[Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers](https://www.researchgate.net/publication/368601884_Using_Camera_Traps_to_Estimate_Medium_and_Large_Mammal_Density_Comparison_of_Methods_and_Recommendations_for_Wildlife_Managers)\" (Clarke et al., 2024)\n",
    ":::\n",
    "\n",
    "A spatial count (SC) model is essentially a spatial capture-recapture (SCR; see {bdg-link-primary-line}`Spatial capture-recapture (SCR) / Spatially explicit capture recapture (SECR)<https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_11_mod_scr_secr.html>`) model with an extension to account for unmarked animals’ unknown identities ({{ ref_intext_royle_et_al_2014 }}). SC, then, is formulated in much the same way as SCR: populations are treated as collections of individual activity (or home range) centres, and spatial detection data is used to infer the number and locations of these activity centres (see {bdg-link-primary-line}`Spatial capture-recapture (SCR) / Spatially explicit capture recapture (SECR)<https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_11_mod_scr_secr.html>`). Instead of identifying animals and constructing individual detection histories (i.e., each individual’s spatial pattern of detections), however, SC uses trap-specific counts (i.e., the tally of animal detections at each trap of known location) and the correlation structure among trapspecific counts to estimate the number and location of activity centres ({{ ref_intext_royle_et_al_2014 }}, {{ ref_intext_sun_et_al_2022 }}).\n",
    "\n",
    "Like SCR, an SC model is composed of a spatial process model and an observation model. The spatial process model, which describes how activity centres are distributed across the landscape, is a homogeneous point-process model – a completely random pattern of points in space (Baddeley, no date; {{ ref_intext_royle_2016 }}). The observation model, which describes where individuals are detected on the landscape, is constructed as if we know each individual’s detection history and the size of the population ({{ ref_intext_chandler_royle_2013 }}). As Royle et al. (2014) put it: “[SC] is formulated in terms of the data we wish we had, i.e., the typical [detection] history data observed in [SCR] studies of marked animals.” We can construct an SC model in this way because trap-specific counts of animals arise from those animals’ detection histories; in other words, counts are a simplified version of the data that would have been collected, had individuals been identifiable ({{ ref_intext_chandler_royle_2013 }}, {{ ref_intext_sun_et_al_2022 }}).\n",
    "\n",
    "To relate trap-specific counts to detection histories, we use the equation: \n",
    "\n",
    "```{figure} ../03_images/03_image_files/ clarke_et_al_2023_eqn_sc1.png\n",
    ":width: 80px\n",
    ":align: center\n",
    "```  \n",
    "\n",
    "where *n<sub>𝑗𝑘</sub>* is the count of animals at sampling location *𝑗* and during sampling period *𝑘*; *𝑁* is population size; and *𝑦<sub>𝑖𝑗𝑘</sub>* is individual 𝑖's detection history at sampling location *𝑗* and during sampling period *𝑘* ({{ ref_intext_royle_et_al_2014 }}). So, the trap- and period-specific count *n<sub>𝑗𝑘</sub>*\n",
    "– the information we gather for SC – is the same as the sum of every individual’s encounter history at that trap – the information we gather for SCR ({{ ref_intext_royle_et_al_2014 }}). \n",
    "\n",
    "To approximate population size, we take a data augmentation approach. Population size *𝑁* is treated as a subset of some larger, hypothetical population of size *𝑀* (the “augmented” population; {{ ref_intext_royle_dorazio_2012 }}), such that: \n",
    "\n",
    "```{figure} ../03_images/03_image_files/ clarke_et_al_2023_eqn_sc2.png\n",
    ":width: 80px\n",
    ":align: center\n",
    "```  \n",
    "\n",
    "where *𝑀* ≫ *𝑁* and *𝜔<sub>𝑖</sub>* is the probability of existence of individual *𝑖* within population *𝑁* ({{ ref_intext_chandler_royle_2013 }}, {{ ref_intext_sun_et_al_2022 }}). *𝜔<sub>𝑖</sub>* is Bernoulli distributed – an animal can be present (i.e., *𝜔<sub>𝑖</sub>* = 1) or absent (i.e., *𝜔<sub>𝑖</sub>* = 0) – and depends on the number of detections at traps and the distance between traps and individuals’ activity centres ({{ ref_intext_chandler_royle_2013 }}, {{ ref_intext_sun_et_al_2022 }}).\n",
    "\n",
    "Note that, for SC, a “trap” is simply a tool or method for collecting count data. Trap types include hair snags, track plates, acoustic recording devices, human point-count observers and camera traps ({{ ref_intext_chandler_royle_2013 }}, {{ ref_intext_royle_et_al_2014 }}). We will refer to camera traps for the remainder of this section. \n",
    "\n",
    "The aim of SC sampling design is to infer the number and location of activity centres by inducing correlation (i.e., linear relation) between the number and location of detections ({{ ref_intext_burgar_et_al_2019 }}, {{ ref_intext_chandler_royle_2013 }}, {{ ref_intext_sollmann_2018 }}, {{ ref_intext_sun_et_al_2022 }}). To this end, camera traps must be deployed close enough together that individuals will be detected at multiple locations ({{ ref_intext_chandler_royle_2013 }}). Grid or clustered designs may be best ({{ ref_intext_burgar_et_al_2019 }}, {{ ref_intext_clarke_2019 }}, {{ ref_intext_sun_et_al_2014 }}).\n",
    "\n",
    "## Simulations and Field Experiments\n",
    "The relatively few studies that have tested SC models suggest that they tend to produce fairly accurate but imprecise density estimates. \n",
    "- A study on fishers showed that, compared to genetic SCR, SC underestimated density and estimates were less precise ({{ ref_intext_burgar_et_al_2018 }}). \n",
    "- Evans and Rittenhouse (2018) found that SC yielded accurate but less precise estimates of black bear density than camera trap SCR. \n",
    "- Another study compared estimates of caribou density from SC with estimates from the spatial partial identity model (SPIM; see {bdg-link-primary-line}`Spatial Partial Identity Model (Categorical SPIM; catSPIM)<https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_15_mod_catspim.html>`and {bdg-link-primary-line}`Spatial Partial Identity Model (2-flank SPIM)<https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_16_mod_2flankspim.html>`). In this system, SC likely underestimated density compared with SPIM – perhaps because the model interpreted captures of many individuals as recaptures of a few individuals – and was less precise and more variable year-toyear ({{ ref_intext_sun_et_al_2022 }}). \n",
    "- SC was used to estimate the densities of caribou, moose, wolf, coyote and black bear populations in the oil sands region of Alberta ({{ ref_intext_burgar_et_al_2019 }}). Estimates for all species were imprecise; some had confidence intervals with upper and lower bounds that differed more than 10-fold. The authors note, however, that other density estimation methods used in the region (e.g., aerial surveys) are not more precise than SC ({{ ref_intext_burgar_et_al_2019 }}). The researchers also simulated their data, finding that SC tended to underestimate density when the number of captures and spatial recaptures (i.e., spatially-correlated detections between cameras) were low. \n",
    "Box 1. The unmarked models that follow estimate density within the collective viewshed area (i.e., the combined fields-of-view of all cameras in a network) and assume that this estimate applies to the larger study area ({{ ref_intext_gilbert_et_al_2021 }}). This is in contrast to spatial capture-recapture (SCR; see {bdg-link-primary-line}`Spatial capture-recapture (SCR) / Spatially explicit capture recapture (SECR)<https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_11_mod_scr_secr.html>`) models and derivatives – including spatial count (SC; see {bdg-link-primary-line}`Spatial count<https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_14_mod_sc.html>`), spatial mark-resight (SMR; see {bdg-link-primary-line}`Spatial mark-resight<https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_13_mod_smr.html>`) and the spatial partial identity model (SPIM; see {bdg-link-primary-line}`Spatial Partial Identity Model (Categorical SPIM; catSPIM)<https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_15_mod_catspim.html>`and {bdg-link-primary-line}`Spatial Partial Identity Model (2-flank SPIM)<https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_16_mod_2flankspim.html>`) – which estimate density over a defined area.\n",
    "::::::\n",
    "\n",
    "::::::{tab-item} Visual resources\n",
    ":::::{grid} 3\n",
    ":gutter: 1\n",
    ":padding: 0\n",
    ":margin: 0\n",
    "\n",
    "::::{grid-item-card} {{ ref_intext_figure1_ref_id }}\n",
    "```{figure} ../03_images/03_image_files/clarke_et_al_2023_eqn_sc1.png\n",
    ":class: img_grid\n",
    "```\n",
    "\n",
    "::::\n",
    "\n",
    "::::{grid-item-card} {{ ref_intext_figure2_ref_id }}\n",
    "```{figure} ../03_images/03_image_files/clarke_et_al_2023_eqn_sc2.png \n",
    ":class: img_grid\n",
    "```\n",
    "\n",
    "::::\n",
    "\n",
    ":::::\n",
    "\n",
    "::::::\n",
    "\n",
    "\n",
    "::::::{tab-item} Shiny apps/Widgets\n",
    "Check back in the future!\n",
    "::::::\n",
    "\n",
    "::::::{tab-item} Analytical tools & Resources\n",
    "| Type | Name | Note | URL |Reference |\n",
    "|:----------------|:-------------------------------|:----------------------------------------------------------------|:----------------------|:----------------------------------------|\n",
    "| resource1_type | resource1_name | resource1_note | resource1_url | {{ ref_bib_resource1_ref_id }} |\n",
    "| resource2_type | resource2_name | resource2_note | resource2_url | {{ ref_bib_resource2_ref_id }} |\n",
    "| resource3_type | resource3_name | resource3_note | resource3_url | {{ ref_bib_resource3_ref_id }} |\n",
    "| resource4_type | resource4_name | resource4_note | resource4_url | {{ ref_bib_resource4_ref_id }} |\n",
    "| resource5_type | resource5_name | resource5_note | resource5_url | {{ ref_bib_resource5_ref_id }} |\n",
    "| resource6_type | resource6_name | resource6_note | resource6_url | {{ ref_bib_resource6_ref_id }} |\n",
    "| resource7_type | resource7_name | resource7_note | resource7_url | {{ ref_bib_resource7_ref_id }} |\n",
    "| resource8_type | resource8_name | resource8_note | resource8_url| {{ ref_bib_resource8_ref_id}} |\n",
    "| resource9_type | resource9_name | resource9_note | resource9_url | {{ ref_bib_resource9_ref_id }} |\n",
    "| resource10_type | resource10_name | resource10_note | resource10_url | {{ ref_bib_resource10_ref_id }} |\n",
    "| resource11_type | resource11_name | resource11_note | resource11_url | {{ ref_bib_resource11_ref_id }} |\n",
    "| resource12_type | resource12_name | resource12_note | resource12_url | {{ ref_bib_resource12_ref_id }} |\n",
    "| resource13_type | resource13_name | resource13_note | resource13_url | {{ ref_bib_resource13_ref_id }} |\n",
    "| resource14_type | resource14_name | resource14_note | resource14_url | {{ ref_bib_resource14_ref_id }} |\n",
    "| resource15_type | resource15_name | resource15_note | resource15_url | {{ ref_bib_resource15_ref_id }} |\n",
    "::::::\n",
    "\n",
    "::::::{tab-item} References\n",
    "{{ ref_bib_burgar_et_al_2018 }}\n",
    "\n",
    "{{ ref_bib_burgar_et_al_2019 }}\n",
    "\n",
    "{{ ref_bib_chandler_royle_2013 }}\n",
    "\n",
    "{{ ref_bib_clarke_2019 }}\n",
    "\n",
    "{{ ref_bib_clarke_et_al_2023 }}\n",
    "\n",
    "{{ ref_bib_evans_rittenhouse_2018 }}\n",
    "\n",
    "{{ ref_bib_gilbert_et_al_2021 }}\n",
    "\n",
    "{{ ref_bib_royle_2016 }}\n",
    "\n",
    "{{ ref_bib_royle_dorazio_2012 }}\n",
    "\n",
    "{{ ref_bib_royle_et_al_2014 }}\n",
    "\n",
    "{{ ref_bib_sun_et_al_2014 }}\n",
    "\n",
    "{{ ref_bib_sun_et_al_2022 }}\n",
    "\n",
    "{{ ref_bib_sollmann_2018 }}\n",
    "\n",
    "{{ ref_bib_gilbert_et_al_2021 }}\t\n",
    "::::::\n",
    "\n",
    ":::::::"
   ]
  }
 ],
 "metadata": {
  "editor_options": {
   "markdown": null,
   "wrap": "none"
  },
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.17.2 <!--0.13-->",
    "jupytext_version": "1.16.4  <!--6.5.2-->"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "source_map": [
   16
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}