
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Random encounter and staying time (REST) &#8212; Remote Camera Decision Support Tool - Concept Library</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy.css?v=7a364cf7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=cf5192f4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/03_18_mod_rest';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="random-encounter-and-staying-time-rest">
<span id="i-mod-rest"></span><h1>Random encounter and staying time (REST)<a class="headerlink" href="#random-encounter-and-staying-time-rest" title="Link to this heading">#</a></h1>
<p><strong>Random encounter and staying time (REST) model (Nakashima et al., 2018)</strong>: A recent modification of the REM (Nakashima et al., 2018) that substitutes staying time (i.e., the cumulative time in the cameras’ detection zone) for movement speed (staying time and movement speed are inversely proportional) (Cappelle et al., 2021).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Assumptions, Pros, Cons</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Assumptions</div>
<ul class="simple">
<li><p class="sd-card-text">Demographic closure (i.e., no births or deaths) and geographic closure (i.e., no immigration or emigration) (animal <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> is constant during the <a class="reference internal" href="09_glossary.html#survey"><span class="std std-ref">survey</span></a>) (Rowcliffe et al., 2008)</p></li>
<li><p class="sd-card-text">Detection is perfect (Wearn &amp; Glover-Kapfer, 2017) (detection probability ‘<em>p</em>’ = 1) unless otherwise modelled (Nakashima et al., 2018)</p></li>
<li><p class="sd-card-text">Camera locations are representative of the available habitat (Nakashima et al., 2018)</p></li>
<li><p class="sd-card-text">Camera locations are randomly placed relative to the spatial distribution of animals (Nakashima et al., 2018)</p></li>
<li><p class="sd-card-text">Animal movement and behaviour are not affected by cameras (Nakashima et al., 2018)</p></li>
<li><p class="sd-card-text">Detections are <a class="reference internal" href="09_glossary.html#independent-detections"><span class="std std-ref">independent</span></a> (Nakashima et al., 2018)</p></li>
<li><p class="sd-card-text">The observed distribution of staying time in the focal area fits the distribution of movement (Nakashima et al., 2018)</p></li>
<li><p class="sd-card-text">The observed staying time must follow a given parametric distribution (Nakashima et al., 2018)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Pros</div>
<ul class="simple">
<li><p class="sd-card-text">Provides unbiased estimates of animal <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a>, even when animal movement speed varies, and animals travel in pairs (Nakashima et al., 2018)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Cons</div>
<ul class="simple">
<li><p class="sd-card-text">Attraction or aversion to cameras is exhibited in some species (Meek et al., 2016) and could affect the time within the detection zone and subsequently affect estimates of <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> (Doran-Myers, 2018)</p></li>
<li><p class="sd-card-text">Requires accurate measurements of the area of the camera detection zone, which has been a challenge in previous studies (Rowcliffe et al., 2011; Cusack et al., 2015; Anile &amp; Devillard, 2016; Doran-Myers, 2018; Nakashima et al., 2018)</p></li>
<li><p class="sd-card-text">Mathematically challenging (Cusack et al., 2015)</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</details><div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Overview</label><div class="sd-tab-content docutils">
<p>This section will be available soon! In the meantime, check out the information in the other tabs!</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/00_coming_soon.png"><img alt="../_images/00_coming_soon.png" src="../_images/00_coming_soon.png" style="width: 300px;" /></a>
</figure>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
Advanced</label><div class="sd-tab-content docutils">
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>This content was adapted from</strong>: The Density Handbook, “<a class="reference external" href="https://www.researchgate.net/publication/368601884_Using_Camera_Traps_to_Estimate_Medium_and_Large_Mammal_Density_Comparison_of_Methods_and_Recommendations_for_Wildlife_Managers">Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</a>” (Clarke et al., 2024)</p>
</div>
<p>The random encounter and staying time (REST) model is an extension of the random encounter model (REM; (Gilbert et al., 2020). Like the REM, the REST treats animals like ideal gas particles (i.e., like randomly and independently moving entities); unlike the REM, the REST does not require measures of animal movement speed. Instead, the model uses the time animals spend in the camera viewshed (i.e., their “staying time”) as a proxy for animal movement speed, since the two measures are inversely proportional (Nakashima et al., 2018).</p>
<p>The REST equation is a modified version of the REM equation which substitutes staying time for movement speed, and a detection area of set size for detection zone radius and angle, such that:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_rest1.png"><img alt="../_images/clarke_et_al_2023_eqn_rest1.png" src="../_images/clarke_et_al_2023_eqn_rest1.png" style="height: 100px;" /></a>
</figure>
<p>where <em>𝑌</em> is the number of detections, <em>𝑇</em> is the staying time, <em>𝑠</em> is the area within which all individuals are certain to be detected (hereafter, focal area), and <em>𝐻</em> is the total research period (i.e., the total sampling time; Nakashima et al., 2018). This equation produces an estimate of density <em>𝐷</em> at a single camera; to determine population density for the study area, density estimates must be averaged across camera stations.</p>
<p>To implement the REST model, practitioners must first establish the focal area <em>𝑠</em>.</p>
<p>Methods at practitioners’ disposal include testing focal areas of different sizes under controlled conditions (e.g., using domestic animals) and determining detection probabilities (Nakashima et al., 2018; Rowcliffe et al., 2014), or using distance sampling (DS) functions to delineate the zone of certain detection (as described in Hofmeester et al. [2017] and implemented in Palencia et al. [2021]). Although it can be any shape, a triangular focal area maximizes the number of usable detections (fewer captures fall outside of the focal area; Nakashima et al., 2018).</p>
<p>Once established, the focal area is staked out in front of every camera in the field (e.g., using ropes and pegs), a reference image is taken, and any staking equipment is removed before the camera is left to collect images or videos (Nakashima et al., 2018, Palencia et al., 2021, 中島啓裕 2021). During image processing, captures of animals are overlaid on reference images (Figure 8A; 中島啓裕 2021). Alternatively, the focal area can be superimposed on captures of animals as in Figure 8B. Markers (e.g., stones) placed at known distances from the camera are used as a guide for placing the focal area (Palencia et al., 2021). Staying time <em>𝑇</em> is the time an animal spends in the focal area; it is measured from the moment an animal’s hind leg enters the focal area until it exits (i.e.,* 𝑇<sub>𝑒𝑥𝑖𝑡</sub> − 𝑇<sub>𝑒𝑛𝑡𝑒𝑟</sub>*).</p>
<p>Importantly, estimates of density <em>𝐷</em> must be corrected for activity level – that is, the proportion of time animals are active – such that:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_rest2.png"><img alt="../_images/clarke_et_al_2023_eqn_rest2.png" src="../_images/clarke_et_al_2023_eqn_rest2.png" style="height: 100px;" /></a>
</figure>
<p>where <em>𝐷̂</em> is the corrected density estimate and 𝑎 is the activity level (Palencia et al., 2021, (Rowcliffe et al., 2014). Activity level is determined as per Rowcliffe et al. (2014).</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_fig8_clipped.png"><img alt="../_images/clarke_et_al_2023_fig8_clipped.png" src="../_images/clarke_et_al_2023_fig8_clipped.png" style="width: 500px;" /></a>
</figure>
<p><strong>Clarke et al. 2023 - Figure 8.</strong> A) Still from 中島啓裕’s (2021) video series. Example of overlaying a video recording of an animal on a Reference image of the focal area (faint triangle) to determine staying time <em>𝑇</em>. B) Still from Appendix S2 from Palencia et al. (2021). Example of superimposing the focal area on an image capture.</p>
<h2 class="rubric" id="simulations-and-field-experiments">Simulations and Field Experiments</h2>
<p>Nakashima et al. (2018) ran random walk simulations to test the REST’s performance. In its simplest form, a random walk models the series of steps an animal (the “walker”) takes – each in a completely arbitrary direction, or in a pattern informed by behaviour, ecology and environment (Codling et al., 2008). Nakashima et al.’s (2018) simulations showed that the REST model was robust to grouping behaviour and variation in animal movement speed. More specifically, the REST produced accurate estimates of density when animals travelled in pairs, and when animals covered different distances during the sampling period (Nakashima et al., 2018). The model produced biased results, however, when captures of animals resting in the focal area were included in staying times (Nakashima et al., 2018). To minimize bias: 1) any detections with exceedingly long staying times (i.e., right outliers) should be discarded; and 2) density estimates should be corrected for activity level <em>𝑎</em> using the method outlined in Rowcliffe et al. (2014; Nakashima et al., 2018).</p>
<p>Garland et al. (2020) ran a “real life” simulation of the REST using human volunteers. The researchers found that the model produced accurate density estimates, even when home range size, population size and movement patterns varied – but that scenarios in which people moved at a constant rate yielded more precise estimates than those in which people rested periodically (Garland et al., 2020). Larger populations were also associated with lower-precision estimates (i.e., the bigger the population, the less precise the density estimate) – as population size increases, so too does the variation in staying times, reducing the overall precision of REST estimates (Garland et al., 2020). Note than humans were fully agnostic to detectors – an assumption often violated by animals (Caravaggi et al., 2020).</p>
<p>Both Garland et al. (2020) and Nakashima et al. (2018) tested the effect of sampling effort on the REST; both concluded that the model can yield accurate results, even when effort is relatively small (1% of study area sampled or 10 cameras deployed for 10 days, respectively). Note, however, that these results pertain to very high-density populations – animal density was 125 to 750 individuals per km2 in Garland et al. (2020) and 10 individuals per km2 in Nakashima et al. (2018) – and likely do not apply to average-to-low density populations. Low sampling effort was also linked to imprecision – the fewer cameras deployed, the less precise the density estimate (Garland et al., 2020; Nakashima et al., 2018). Thus, although little sampling effort is needed to produce accurate density estimates for very dense populations, considerable sampling effort will be necessary for most populations, and to produce precise estimates.</p>
<h2 class="rubric" id="in-the-field">In the field</h2>
<ul class="simple">
<li><p>The REST was initially validated by Nakashima et al. (2018), who compared density estimates of forest-dwelling antelopes from the camera data-based model and line-transect surveys (see *2.2.2 Distance Sampling[in Clarke et al. 2023]**). In this system, both methods produced similar estimates of antelope density, with similar precision (Nakashima et al., 2018). A follow-up study in the same area further demonstrated that the model can produce unbiased estimates of density (Nakashima et al., 2020).</p></li>
<li><p>The model produced estimates of snowshoe hare density comparable to livetrapping SCR in the boreal forest of the northwestern United States (Jensen et al., 2022). REST- and REM-based estimates were also consistent with each other, and both models outperformed the time-to-event model (TTE; see <em>2.2.6 Time-toEvent Model</em>[in Clarke et al. 2023]*; Jensen et al., 2022).</p></li>
<li><p>Palencia et al. (2021) found that REST-derived density estimates were consistent with line-transect surveys of deer, but not with drive-count surveys of boar; the REST underestimated density compared to the latter. The model was, however, highly consistent with the REM and camera trap distance sampling (DS; Palencia et al., 2021). Furthermore, the REST was more precise than the other two camera models – although not significantly (Palencia et al., 2021)</p></li>
<li></li>
</ul>
<p>Practitioners should be aware that population densities were quite high in the studies listed above (about 1 to 160 animals per km2; Jensen et al., 2022; Nakashima et al., 2018). Thus, while the REST model applies well to very dense populations, it may not be appropriate for average-to-low density populations (e.g., wildlife populations in BC, with densities often &lt;1 animal/km2); further investigation is needed (Morin et al., 2022). The precision of the REST is also inversely related to population size – the smaller the population, the less precise the density estimate (Morin et al., 2022).</p>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
Visual resources</label><div class="sd-tab-content docutils">
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_rest1.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_rest1.png" />
</figure>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_rest2.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_rest2.png" />
</figure>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_fig8_clipped.png" class="img-grid" src="../_images/clarke_et_al_2023_fig8_clipped.png" />
</figure>
<p class="sd-card-text">**Clarke et al. (2023) – Fig. 8 ** A) Still from 中島啓裕’s (2021) video series. Example of overlaying a video recording of an animal on a Reference image of the focal area (faint triangle) to determine staying time <em>𝑇</em>. B) Still from Appendix S2 from Palencia et al. (2021). Example of superimposing the focal area on an image capture.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-3">
Shiny apps/Widgets</label><div class="sd-tab-content docutils">
<p>Check back in the future!</p>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-4">
Analytical tools &amp; resources</label><div class="sd-tab-content docutils">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Type</p></th>
<th class="head text-left"><p>Name</p></th>
<th class="head text-left"><p>Note</p></th>
<th class="head text-left"><p>URL</p></th>
<th class="head text-left"><p>Reference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>resource1_type</p></td>
<td class="text-left"><p>resource1_name</p></td>
<td class="text-left"><p>resource1_note</p></td>
<td class="text-left"><p>resource1_url</p></td>
<td class="text-left"><p>ref_bib_resource1_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource2_type</p></td>
<td class="text-left"><p>resource2_name</p></td>
<td class="text-left"><p>resource2_note</p></td>
<td class="text-left"><p>resource2_url</p></td>
<td class="text-left"><p>ref_bib_resource2_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource3_type</p></td>
<td class="text-left"><p>resource3_name</p></td>
<td class="text-left"><p>resource3_note</p></td>
<td class="text-left"><p>resource3_url</p></td>
<td class="text-left"><p>ref_bib_resource3_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource4_type</p></td>
<td class="text-left"><p>resource4_name</p></td>
<td class="text-left"><p>resource4_note</p></td>
<td class="text-left"><p>resource4_url</p></td>
<td class="text-left"><p>ref_bib_resource4_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource5_type</p></td>
<td class="text-left"><p>resource5_name</p></td>
<td class="text-left"><p>resource5_note</p></td>
<td class="text-left"><p>resource5_url</p></td>
<td class="text-left"><p>ref_bib_resource5_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource6_type</p></td>
<td class="text-left"><p>resource6_name</p></td>
<td class="text-left"><p>resource6_note</p></td>
<td class="text-left"><p>resource6_url</p></td>
<td class="text-left"><p>ref_bib_resource6_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource7_type</p></td>
<td class="text-left"><p>resource7_name</p></td>
<td class="text-left"><p>resource7_note</p></td>
<td class="text-left"><p>resource7_url</p></td>
<td class="text-left"><p>ref_bib_resource7_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource8_type</p></td>
<td class="text-left"><p>resource8_name</p></td>
<td class="text-left"><p>resource8_note</p></td>
<td class="text-left"><p>resource8_url</p></td>
<td class="text-left"><p>ref_bib_resource8_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource9_type</p></td>
<td class="text-left"><p>resource9_name</p></td>
<td class="text-left"><p>resource9_note</p></td>
<td class="text-left"><p>resource9_url</p></td>
<td class="text-left"><p>ref_bib_resource9_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource10_type</p></td>
<td class="text-left"><p>resource10_name</p></td>
<td class="text-left"><p>resource10_note</p></td>
<td class="text-left"><p>resource10_url</p></td>
<td class="text-left"><p>ref_bib_resource10_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource11_type</p></td>
<td class="text-left"><p>resource11_name</p></td>
<td class="text-left"><p>resource11_note</p></td>
<td class="text-left"><p>resource11_url</p></td>
<td class="text-left"><p>ref_bib_resource11_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource12_type</p></td>
<td class="text-left"><p>resource12_name</p></td>
<td class="text-left"><p>resource12_note</p></td>
<td class="text-left"><p>resource12_url</p></td>
<td class="text-left"><p>ref_bib_resource12_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource13_type</p></td>
<td class="text-left"><p>resource13_name</p></td>
<td class="text-left"><p>resource13_note</p></td>
<td class="text-left"><p>resource13_url</p></td>
<td class="text-left"><p>ref_bib_resource13_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource14_type</p></td>
<td class="text-left"><p>resource14_name</p></td>
<td class="text-left"><p>resource14_note</p></td>
<td class="text-left"><p>resource14_url</p></td>
<td class="text-left"><p>ref_bib_resource14_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource15_type</p></td>
<td class="text-left"><p>resource15_name</p></td>
<td class="text-left"><p>resource15_note</p></td>
<td class="text-left"><p>resource15_url</p></td>
<td class="text-left"><p>ref_bib_resource15_ref_id</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-5">
References</label><div class="sd-tab-content docutils">
<p>Caravaggi, A., Burton, A. C., Clark, D. A., Fisher, J. T., Grass, A., Green, S., Hobaiter, C., Hofmeester, T. R., Kalan, A. K., Rabaiotti, D., &amp; Rivet, D. (2020). A Review of Factors To Consider When Using Camera Traps To Study Animal Behavior To Inform Wildlife Ecology And Conservation. <em>Conservation Science and Practice, 2</em>(8). <a class="reference external" href="https://doi.org/10.1111/csp2.239">https://doi.org/10.1111/csp2.239</a></p>
<p>Clarke, J., Bohm, H., Burton, C., Constantinou, A. (2023). <em>Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</em>. <a class="reference external" href="https://doi.org/10.13140/RG.2.2.18364.72320">https://doi.org/10.13140/RG.2.2.18364.72320</a></p>
<p>Codling, E. A., Plank, M. J., &amp; Benhamou, S. (2008). Random walk models in biology. <em>Journal of The Royal Society Interface, 5</em>(25), 813–834. <a class="reference external" href="https://doi.org/10.1098/rsif.2008.0014">https://doi.org/10.1098/rsif.2008.0014</a></p>
<p>Garland, L., Neilson, E., Avgar, T., Bayne, E., &amp; Boutin, S. (2020). Random Encounter and Staying Time Model Testing with Human Volunteers. <em>The Journal of Wildlife Management, 84</em>(6), 1179–1184. <a class="reference external" href="https://doi.org/10.1002/jwmg.21879">https://doi.org/10.1002/jwmg.21879</a></p>
<p>Gilbert, N. A., Clare, J. D. J., Stenglein, J. L., &amp; Zuckerberg, B. (2020). Abundance Estimation of Unmarked Animals based on Camera-Trap Data. <em>Conservation Biology, 35</em>(1), 88-100. <a class="reference external" href="https://doi.org/10.1111/cobi.13517">https://doi.org/10.1111/cobi.13517</a>)</p>
<p>Hofmeester, T. R., Rowcliffe, J. M., Jansen, P. A., Williams, R., &amp; Kelly, N. (2017). A simple method for estimating the effective detection distance of camera traps. <em>Remote Sensing in Ecology and Conservation, 3</em>(2), 81–89. <a class="reference external" href="https://doi.org/10.1002/rse2.25">https://doi.org/10.1002/rse2.25</a>)</p>
<p>Jensen, P. O., Wirsing, A. J., &amp; Thornton, D. H. (2022). Using camera traps to estimate density of snowshoe hare ( Lepus americanus ): A keystone boreal forest herbivore. <em>Journal of Mammalogy, 103</em>(3), 693–710. <a class="reference external" href="https://doi.org/10.1093/jmammal/gyac009">https://doi.org/10.1093/jmammal/gyac009</a></p>
<p>Morin, D. J., Boulanger, J., Bischof, R., Lee, D. C., Ngoprasert, D., Fuller, A. K., McLellan, B., Steinmetz, R., Sharma, S., Garshelis, D., Gopalaswamy, A., Nawaz, M. A., &amp; Karanth, U. (2022).comparison of methods for estimating Density and population trends for low-Density Asian bears. <em>Global Ecology and Conservation, 35</em>, e02058 <a class="reference external" href="https://doi.org/10.1016/j.gecco.2022.e02058">https://doi.org/10.1016/j.gecco.2022.e02058</a></p>
<p>Nakashima, Y., Hongo, S., &amp; Akomo-Okoue, E. F. (2020). Landscape-scale estimation of forest ungulate density and biomass using camera traps: Applying the REST model. <em>Biological Conservation, 241</em>, 108381. <a class="reference external" href="https://doi.org/10.1016/j.biocon.2019.108381">https://doi.org/10.1016/j.biocon.2019.108381</a></p>
<p>Palencia, P., Rowcliffe, J. M., Vicente, J., &amp; Acevedo, P. (2021). Assessing the camera trap methodologies used to estimate Density of unmarked populations. <em>Journal of Applied Ecology, 58</em>(8), 1583–1592. <a class="reference external" href="https://doi.org/10.1111/1365-2664.13913">https://doi.org/10.1111/1365-2664.13913</a></p>
<p>Rowcliffe, J. M., Kays, R., Kranstauber, B., Carbone, C., Jansen, P. A., &amp; Fisher, D. (2014). Quantifying levels of animal activity using camera trap data. <em>Methods in Ecology and Evolution</em>, <em>5</em>(11), 1170–1179. <a class="reference external" href="https://doi.org/10.1111/2041-210x.12278">https://doi.org/10.1111/2041-210x.12278</a></p>
<p>中島啓裕’s (2021)</p>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              
              
              
              
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>