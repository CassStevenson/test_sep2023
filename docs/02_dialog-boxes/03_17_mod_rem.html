
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Random encounter model (REM) &#8212; Remote Camera Decision Support Tool - Concept Library</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy.css?v=7a364cf7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=c483416e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/03_17_mod_rem';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="random-encounter-model-rem">
<span id="i-mod-rem"></span><h1>Random encounter model (REM)<a class="headerlink" href="#random-encounter-model-rem" title="Link to this heading">#</a></h1>
<p><strong>Random encounter model (REM) (Rowcliffe et al., 2008, 2013)</strong>: A method used to estimate the <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> of unmarked populations; uses the rate of independent captures, an estimate of movement rate, average group size, and the area sampled by the remote camera.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Assumptions, Pros, Cons</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Assumptions</div>
<ul class="simple">
<li><p class="sd-card-text">Demographic closure (Rowcliffe et al., 2008; Doran-Myers, 2018) (i.e., no births or deaths)</p></li>
<li><p class="sd-card-text">Geographic closure (Rowcliffe et al., 2008; Doran-Myers, 2018) (i.e., no immigration or emigration) (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Camera locations are randomly placed relative to animal movement (Wearn &amp; Glover-Kapfer, 2017; Rowcliffe et al., 2008)</p></li>
<li><p class="sd-card-text">Animal movement is unaffected by the cameras (Wearn &amp; Glover-Kapfer, 2017; Rowcliffe et al., 2008)</p></li>
<li><p class="sd-card-text">Accurate counts of independent ‚Äòcontacts‚Äô camera locations (Wearn &amp; Glover-Kapfer, 2017; Rowcliffe et al., 2008)</p></li>
<li><p class="sd-card-text">Unbiased estimates of animal activity levels and speed (Rowcliffe et al., 2014; Rowcliffe et al., 2016; Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Camera‚Äôs detection zone can be approximated well using a 2D cone shape, defined by the radius and angle parameters (Rowcliffe et al., 2011)</p></li>
<li><p class="sd-card-text">If activity and speed are to be estimated from camera data, two additional assumptions: All animals are active during the peak daily activity (Rowcliffe et al., 2014)</p></li>
<li><p class="sd-card-text">Animals moving quickly past a camera are not missed (Rowcliffe et al., 2016)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Pros</div>
<ul class="simple">
<li><p class="sd-card-text">Flexible study design (e.g., ‚Äòholes‚Äô in grids allowed, camera spacing less important) (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Can be applied to unmarked species (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Allows community-wide <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> estimation (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Outputs also include informative parameter estimates (i.e., animal speed and activity levels, and detection zone parameters) (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Comparable estimates to SECR [(Efford, 2004; Borchers &amp; Efford, 2008; Royle &amp; Young, 2008; Royle et al., 2009) (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Does not require marked animals or identification of individuals (Rowcliffe et al., 2008; Doran-Myers, 2018)</p></li>
<li><p class="sd-card-text">Can use camera spacing without regard to population home range size (Rowcliffe et al., 2008; Doran-Myers, 2018)</p></li>
<li><p class="sd-card-text">Direct estimation of <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a>; avoids ad-hoc definitions of study area (Rowcliffe et al., 2008)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Cons</div>
<ul class="simple">
<li><p class="sd-card-text">Requires relatively stringent study design, particularly (e.g., random sampling and use of bait or lure) (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Requires independent estimates of animal speed or measurement of animal speed within videos (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">No dedicated, simple software (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Random relative to animal movement, grid preferred, avoid multiple captures of same individual, area coverage important for abundance estimation (Rovero et al., 2013)</p></li>
<li><p class="sd-card-text">Possible sources of error include inaccurate measurement of detection zone and movement rate (Rowcliffe et al., 2013; Cusack et al., 2015)</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</details><div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Overview</label><div class="sd-tab-content docutils">
<p>This section will be available soon! In the meantime, check out the information in the other tabs!</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/00_coming_soon.png"><img alt="../_images/00_coming_soon.png" src="../_images/00_coming_soon.png" style="width: 300px;" /></a>
</figure>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
In-depth</label><div class="sd-tab-content docutils">
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>This content was adapted from</strong>: The Density Handbook, ‚Äú<a class="reference external" href="https://www.researchgate.net/publication/368601884_Using_Camera_Traps_to_Estimate_Medium_and_Large_Mammal_Density_Comparison_of_Methods_and_Recommendations_for_Wildlife_Managers">Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</a>‚Äù (Clarke et al.. 2024)</p>
</div>
<p>The random encounter model (REM) treats animals like ideal gas particles ‚Äì that is, like randomly moving entities which are neither attracted to nor repelled by one another or landscape features (Gilbert et al., 2020; Rowcliffe et al., 2008
). If animals behave like ideal gas particles, the rate at which they ‚Äúbump into‚Äù and trigger camera traps is a function of animal movement, population density and the area within which cameras detect animals (Nakashima et al., 2017). So, the more animals move, the more animals in a population, or the larger the viewshed ‚Äì the more images will be captured (Palencia et al., 2022). This relationship can be used to estimate density, such that:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_rem1.png"><img alt="../_images/clarke_et_al_2023_eqn_rem1.png" src="../_images/clarke_et_al_2023_eqn_rem1.png" style="width: 242.39999999999998px; height: 79.2px;" /></a>
</figure>
<p>where <em>ùëå</em> is the number of detection events, <em>ùëá</em> is the total sampling time and ùë£ is animal movement speed (or the distance travelled by an individual in a day); and <em>ùëü</em> and <em>ùúÉ</em>, the mean radius and angle of the detection zone (i.e., the area within which animals are detected with certainty) are used to calculate the area of the detection zone (Nakashima et al., 2017; Pettigrew et al., 2021; Rowcliffe et al., 2008).</p>
<p>Independent estimates of <em>ùë£</em> can be sourced from telemetric studies, estimated from intensive observation or calculated using camera trap data (Nakashima et al., 2017, Rowcliffe et al., 2008, Rowcliffe et al., 2016). To calculate ùë£ using camera traps: for each observation, practitioners should determine how long it took the animal to pass through the viewshed (i.e., time between first and last image in a sequence), then measure the distance the animal travelled by either a) retracing their path in the field using photos as a guide or b) estimating their movement image-to-image during photo processing using markers (Pfeffer et al., 2018, Rowcliffe et al., 2016).</p>
<p><em>ùëü</em> and <em>ùúÉ</em> can be measured in a few different ways. The first is by field trial: the detection zone is delineated by approaching the camera trap from different angles and at different speeds, recording where the sensor is triggered (Figure 7; Rowcliffe et al., 2008). The second is using a distance sampling method described in Rowcliffe et al. (2011). The third is by setting a focal area of standard size and shape (i.e., of known ùëü and ùúÉ), within which detection is assumed to be perfect; only animals captured within the focal area are considered for analyses (Nakashima et al., 2017). <em>ùúÉ</em> may also be specified by the manufacturer (Pettigrew et al., 2021).</p>
<p>When the species of interest travels in packs or herds, density as calculated per the equation above represents group density (i.e., the number of groups per unit area; Rowcliffe et al., 2008). To convert group density to individual density, <em>ùê∑</em> must be multiplied by an independent estimate of average group size (Rowcliffe et al., 2008).</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_fig7_clipped.png"><img alt="../_images/clarke_et_al_2023_fig7_clipped.png" src="../_images/clarke_et_al_2023_fig7_clipped.png" style="width: 117.0px; height: 125.39999999999999px;" /></a>
</figure>
<p><strong>Clarke et al. (2023) - Fig. 7</strong> Measuring <em>ùëü</em> and <em>ùúÉ</em> by field trial. The perimeter of the detection zone is determined by approaching the camera from different angles and at different speeds, and noting where the camera‚Äôs sensor (red flash) detects motion (red dots).</p>
<h2 class="rubric" id="simulations-and-field-experiments">Simulations and Field Experiments</h2>
<p>Of all the unmarked density models, the REM has undergone the most empirical testing (Palencia et al., 2021). Rowcliffe et al. (2008) piloted the model in an enclosed animal park housing populations of known sizes, and found that the REM produced accurate density estimates for three out of four target species (two cervids and a marsupial). The model underestimated the density of the fourth species (a large rodent) because cameras were deployed in habitats it did not frequent ‚Äì a violation of assumption 3 (Rowcliffe et al., 2008).</p>
<p>The REM has proven robust in many study systems. Examples include:</p>
<ul class="simple">
<li><p>Palencia et al. (2021) found that the REM yielded similar density estimates as two non-camera methods, line-transect sampling and drive counts, for red deer and wild boar, respectively. The researchers also compared the REM to two other camera methods (random encounter and staying time (REST) and distance sampling (DS) models) ‚Äì of the three, the REM was the most consistent (Palencia et al., 2021). In this study, animal movement speed <em>ùë£</em> was determined using camera trap data.</p></li>
<li><p>REM-derived density estimates of a mountain ungulate were highly consistent with visual count survey results (Kavƒçiƒá et al., 2021). Animal movement speed was measured using camera trap data (Kavƒçiƒá et al., 2021).</p></li>
<li><p>A study on black bears in Qu√©bec found that the REM produced comparable results to DNA mark-recapture using hair samples, but that REM estimates were less precise (Pettigrew et al., 2021). The researchers estimated animal movement speed by averaging 19 years of telemetry data from four neighbouring black bear populations (Pettigrew et al., 2021).</p></li>
<li><p>In the boreal forest of Washington state, REM and live-trapping spatial capturerecapture (SCR) produced similar density estimates for snowshoe hare (Jensen et al., 2022). The REM and the REST performed identically in this system; both models outperformed the time-to-event (TTE) model (Jensen et al., 2022). Measures of animal movement speed <em>ùë£</em> were pulled from camera data and combined with telemetry data from a study in the Yukon.</p></li>
<li><p>The REM yielded similar density estimates as, and was more precise than, livetrapping SCR at almost 90% of sampling sites in a study of hedgehogs (Schaus et al., 2020). Moreover, the REM was powerful enough to detect a 25% population change in this system (Schaus et al., 2020). Animal movement speed was estimated from camera trap images.</p></li>
</ul>
<p>The REM has also significantly over and underestimated the densities of natural populations. In Africa, for example, estimates of lioness density using the REM were significantly higher than from pride censuses (Cusack et al., 2015). REM-derived densities skewed high because cameras were placed under shady trees, which attracted lions in the daytime (a violation of assumption 3), inflating the number of detection events <em>ùëå</em> (Cusack et al., 2015). When only nighttime detections were considered, however, REM-derived densities did not differ significantly from censusderived densities (Cusack et al., 2015). <em>ùë£</em>, animal movement speed, was determined via intensive observation. A study comparing the REM with fecal DNA mark-recapture found that the REM underestimated marten density by 60% or more (Balestrieri et al., 2016). Animal movement speed ùë£ may have biased density low; the researchers estimated ùë£ from studies of pine marten occupying a different kind of habitat, where individuals may have moved more (Balestrieri et al., 2016).</p>
<p>Simulations suggest that, to achieve adequate precision using the REM, a minimum of 20 to 40 camera stations should be deployed for as long as needed to collect at least 10 to 20 image sets (Rowcliffe et al., 2008). For populations with variable detection: about 100 cameras are needed to obtain a level of precision appropriate for wildlife management (coefficient of variation (CV) of 0.20 or less; Palencia et al., 2021, Williams et al., 2002). To collect 10 to 20 image sets takes approximately 100 to 1,000 camera trap days for most mammal species; for rare species, cameras may need to be deployed for 1,000 camera trap days or more (Rowcliffe et al., 2008).</p>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
Visual resources</label><div class="sd-tab-content docutils">
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_rem1.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_rem1.png" />
</figure>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_fig7_clipped.png" class="img-grid" src="../_images/clarke_et_al_2023_fig7_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Clarke et al. (2023) - Fig. 7</strong> Measuring <em>ùëü</em> and <em>ùúÉ</em> by field trial. The perimeter of the detection zone is determined by approaching the camera from different angles and at different speeds, and noting where the camera‚Äôs sensor (red flash) detects motion (red dots).</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Henrich et al., 2022</div>
<figure class="align-default">
<img alt="../_images/henrich_et_al_2022_fig1_clipped.png" class="img-grid" src="../_images/henrich_et_al_2022_fig1_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Henrich et al. (2022) - Fig. 1</strong> Potential problems caused by animal behavior in the estimation of population densities of unmarked animal species using camera traps and our proposed solutions.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Rowcliffe et al., 2008</div>
<figure class="align-default">
<img alt="../_images/rowcliffe_et_al_2008_fig1_clipped.png" class="img-grid" src="../_images/rowcliffe_et_al_2008_fig1_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Rowcliffe et al. (2008) - Fig. 1</strong> Diagram illustrating the variation in profile presented to animals approaching from different angles by a segment-shaped camera trap detection zone.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-kebab-horizontal no-title" viewBox="0 0 24 24" aria-hidden="true"><path d="M20 14a2 2 0 1 1-.001-3.999A2 2 0 0 1 20 14ZM6 12a2 2 0 1 1-3.999.001A2 2 0 0 1 6 12Zm8 0a2 2 0 1 1-3.999.001A2 2 0 0 1 14 12Z"></path></svg></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Approach directions are indicated by arrows, the detection zone is the shaded segment, defined by radial distance r and angle Œ∏, and the profiles presented are indicated by heavy lines. Six limiting cases are shown for œÄ approach angles, with five resulting transitions. The angles opposite the profiles, Œ≥, are indicated for transitions 1, 2, 4 and 5 (the profile for transition 3 is constant so no such angle is required). The widths of profiles and ranges of Œ≥ for each transition are given by: transitions 1 and 5, 2r sin(Œ∏/2) sin(Œ≥), (œÄ ‚Äì Œ∏)/ 2 ‚â§ Œ≥ ‚â§ œÄ/2; transitions 2 and 4, r sin(Œ≥), Œ∏ ‚â§ Œ≥ ‚â§ œÄ/2; transition 3, r for Œ∏ approach angles.</p>
</div>
</details></div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Rowcliffe et al., 2008</div>
<figure class="align-default">
<img alt="../_images/rowcliffe_et_al_2008_fig4_clipped.png" class="img-grid" src="../_images/rowcliffe_et_al_2008_fig4_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Rowcliffe et al. (2008) - Fig. 4</strong> The precision of estimated density from simulated data in relation to variation in sampling effort, assuming high or low variance in camera trapping rate (upper and lower curves, respectively, in each graph).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-kebab-horizontal no-title" viewBox="0 0 24 24" aria-hidden="true"><path d="M20 14a2 2 0 1 1-.001-3.999A2 2 0 0 1 20 14ZM6 12a2 2 0 1 1-3.999.001A2 2 0 0 1 6 12Zm8 0a2 2 0 1 1-3.999.001A2 2 0 0 1 14 12Z"></path></svg></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Effort is varied as either (a) the number of cameras while holding time per camera constant; (b) the time per camera (indexed by the total number of photographs taken) while holding the number of cameras constant; and (c) the number of camera placements while holding the total amount of camera time constant.</p>
</div>
</details></div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Rowcliffe et al., 2008</div>
<figure class="align-default">
<img alt="../_images/rowcliffe_et_al_2008_fig5_clipped.png" class="img-grid" src="../_images/rowcliffe_et_al_2008_fig5_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Rowcliffe et al. (2008) - Fig. 5</strong> Expected trapping effort (camera days, indicated by contours) required to achieve 10 photographs given varying density and day range, assuming a group size of 1.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-kebab-horizontal no-title" viewBox="0 0 24 24" aria-hidden="true"><path d="M20 14a2 2 0 1 1-.001-3.999A2 2 0 0 1 20 14ZM6 12a2 2 0 1 1-3.999.001A2 2 0 0 1 6 12Zm8 0a2 2 0 1 1-3.999.001A2 2 0 0 1 14 12Z"></path></svg></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Typical combinations of day range and density are indicated for carnivores (C), ungulates (U) and rodents (R), calculated using allometric equations for day range and density at carrying capacity (see text) and illustrating densities between 10% and 100% of carrying capacity.</p>
</div>
</details></div>
</div>
</div>
</div>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Palencia &amp; Project ENETWILD, 2022</div>
<iframe 
    width="100%"
    height="300"
    src="https://www.youtube.com/embed/NUW4oLGeQwk?si=isAJ3uO31eANSkDv"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
</iframe>
<p class="sd-card-text">Camera Trap Methods for Density Estimation</p>
</div>
</div>
</div>
</div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-3">
Shiny apps/Widgets</label><div class="sd-tab-content docutils">
<p>Check back in the future!</p>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-4">
Analytical tools &amp; resources</label><div class="sd-tab-content docutils">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Type</p></th>
<th class="head text-left"><p>Name</p></th>
<th class="head text-left"><p>Note</p></th>
<th class="head text-left"><p>URL</p></th>
<th class="head text-left"><p>Reference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>resource1_type</p></td>
<td class="text-left"><p>resource1_name</p></td>
<td class="text-left"><p>resource1_note</p></td>
<td class="text-left"><p>resource1_url</p></td>
<td class="text-left"><p>ref_bib_resource1_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource2_type</p></td>
<td class="text-left"><p>resource2_name</p></td>
<td class="text-left"><p>resource2_note</p></td>
<td class="text-left"><p>resource2_url</p></td>
<td class="text-left"><p>ref_bib_resource2_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource3_type</p></td>
<td class="text-left"><p>resource3_name</p></td>
<td class="text-left"><p>resource3_note</p></td>
<td class="text-left"><p>resource3_url</p></td>
<td class="text-left"><p>ref_bib_resource3_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource4_type</p></td>
<td class="text-left"><p>resource4_name</p></td>
<td class="text-left"><p>resource4_note</p></td>
<td class="text-left"><p>resource4_url</p></td>
<td class="text-left"><p>ref_bib_resource4_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource5_type</p></td>
<td class="text-left"><p>resource5_name</p></td>
<td class="text-left"><p>resource5_note</p></td>
<td class="text-left"><p>resource5_url</p></td>
<td class="text-left"><p>ref_bib_resource5_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource6_type</p></td>
<td class="text-left"><p>resource6_name</p></td>
<td class="text-left"><p>resource6_note</p></td>
<td class="text-left"><p>resource6_url</p></td>
<td class="text-left"><p>ref_bib_resource6_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource7_type</p></td>
<td class="text-left"><p>resource7_name</p></td>
<td class="text-left"><p>resource7_note</p></td>
<td class="text-left"><p>resource7_url</p></td>
<td class="text-left"><p>ref_bib_resource7_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource8_type</p></td>
<td class="text-left"><p>resource8_name</p></td>
<td class="text-left"><p>resource8_note</p></td>
<td class="text-left"><p>resource8_url</p></td>
<td class="text-left"><p>ref_bib_resource8_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource9_type</p></td>
<td class="text-left"><p>resource9_name</p></td>
<td class="text-left"><p>resource9_note</p></td>
<td class="text-left"><p>resource9_url</p></td>
<td class="text-left"><p>ref_bib_resource9_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource10_type</p></td>
<td class="text-left"><p>resource10_name</p></td>
<td class="text-left"><p>resource10_note</p></td>
<td class="text-left"><p>resource10_url</p></td>
<td class="text-left"><p>ref_bib_resource10_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource11_type</p></td>
<td class="text-left"><p>resource11_name</p></td>
<td class="text-left"><p>resource11_note</p></td>
<td class="text-left"><p>resource11_url</p></td>
<td class="text-left"><p>ref_bib_resource11_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource12_type</p></td>
<td class="text-left"><p>resource12_name</p></td>
<td class="text-left"><p>resource12_note</p></td>
<td class="text-left"><p>resource12_url</p></td>
<td class="text-left"><p>ref_bib_resource12_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource13_type</p></td>
<td class="text-left"><p>resource13_name</p></td>
<td class="text-left"><p>resource13_note</p></td>
<td class="text-left"><p>resource13_url</p></td>
<td class="text-left"><p>ref_bib_resource13_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource14_type</p></td>
<td class="text-left"><p>resource14_name</p></td>
<td class="text-left"><p>resource14_note</p></td>
<td class="text-left"><p>resource14_url</p></td>
<td class="text-left"><p>ref_bib_resource14_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource15_type</p></td>
<td class="text-left"><p>resource15_name</p></td>
<td class="text-left"><p>resource15_note</p></td>
<td class="text-left"><p>resource15_url</p></td>
<td class="text-left"><p>ref_bib_resource15_ref_id</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-5">
References</label><div class="sd-tab-content docutils">
<p>Balestrieri, A., Ruiz-Gonz√°lez, A., Vergara, M., Capelli, E., Tirozzi, P., Alfino, S., Minuti, G., Prigioni, C., &amp; Saino, N. (2016). Pine marten density in lowland riparian woods: A test of the Random Encounter Model based on genetic data. <em>Mammalian Biology, 81</em>(5), 439‚Äì446. <a class="reference external" href="https://doi.org/10.1016/j.mambio.2016.05.005">https://doi.org/10.1016/j.mambio.2016.05.005</a></p>
<p>Cusack, J., Dickman, A. J., Rowcliffe, J. M., Carbone, C., Macdonald, D. W., &amp; Coulson, T. (2015). Random versus Game Trail-based Camera trap Placement Strategy for Monitoring Terrestrial Mammal Communities. <em>PloS One</em>,<em>10</em>(5), e0126373. <a class="reference external" href="https://doi.org/10.1371/journal.pone.0126373">https://doi.org/10.1371/journal.pone.0126373</a></p>
<p>Gilbert, N. A., Clare, J. D. J., Stenglein, J. L., &amp; Zuckerberg, B. (2020). Abundance Estimation of Unmarked Animals based on Camera-Trap Data. <em>Conservation Biology, 35</em>(1), 88-100. <a class="reference external" href="https://doi.org/10.1111/cobi.13517">https://doi.org/10.1111/cobi.13517</a></p>
<p>Henrich, M., Hartig, F., Dormann, C. F., K√ºhl, H. S., Peters, W., Franke, F., Peterka, T., ≈†ustr, P., &amp; Heurich, M. (2022). Deer Behavior Affects Density Estimates With Camera Traps, but Is Outweighed by Spatial Variability. <em>Frontiers in Ecology and Evolution, 10</em>, 881502. <a class="reference external" href="https://doi.org/10.3389/fevo.2022.881502">https://doi.org/10.3389/fevo.2022.881502</a></p>
<p>Jensen, P. O., Wirsing, A. J., &amp; Thornton, D. H. (2022). Using camera traps to estimate density of snowshoe hare ( Lepus americanus ): A keystone boreal forest herbivore. <em>Journal of Mammalogy, 103</em>(3), 693‚Äì710. <a class="reference external" href="https://doi.org/10.1093/jmammal/gyac009">https://doi.org/10.1093/jmammal/gyac009</a></p>
<p>Kavƒçiƒá, K., Palencia, P., Apollonio, M., Vicente, J., &amp; ≈†prem, N. (2021). Random encounter model to estimate density of mountain-dwelling ungulate. <em>European Journal of Wildlife Research, 67</em>(5), 87. <a class="reference external" href="https://doi.org/10.1007/s10344-021-01530-1">https://doi.org/10.1007/s10344-021-01530-1</a></p>
<p>Nakashima, Y., Fukasawa, &amp; K., Samejima, H. (2017). Estimating Animal Density Without Individual Recognition Using Information Derivable Exclusively from Camera Traps. <em>Journal of Applied Ecology, 55</em>(2), 735‚Äì744. <a class="reference external" href="https://doi.org/10.1111/1365-2664.13059">https://doi.org/10.1111/1365-2664.13059</a></p>
<p>Palencia, P., Rowcliffe, J. M., Vicente, J., &amp; Acevedo, P. (2021). Assessing the camera trap methodologies used to estimate Density of unmarked populations. <em>Journal of Applied Ecology, 58</em>(8), 1583‚Äì1592. <a class="reference external" href="https://doi.org/10.1111/1365-2664.13913">https://doi.org/10.1111/1365-2664.13913</a></p>
<p>Palencia, P., Vicente, J., Soriguer, R. C., &amp; Acevedo, P. (2022). Towards a best‚Äêpractices guide for camera trapping: assessing differences among camera trap models and settings under field conditions. <em>Journal of Zoology, 316</em>(3), 197‚Äì208. <a class="reference external" href="https://doi.org/10.1111/jzo.12945">https://doi.org/10.1111/jzo.12945</a></p>
<p>Palencia, P. &amp; Project ENETWILD (2022, May 19). <em>Camera Trap Methods for Density Estimation.</em>  [Video]. YouTube. <a class="reference external" href="https://www.youtube.com/watch?v=NUW4oLGeQwk">https://www.youtube.com/watch?v=NUW4oLGeQwk</a></p>
<p>Pettigrew, P., Sigouin, D., &amp; St‚ÄêLaurent, M. (2021). Testing the precision and sensitivity of density estimates obtained with a camera‚Äêtrap method revealed limitations and opportunities. <em>Ecology and Evolution, 11</em>(12), 7879‚Äì7889. <a class="reference external" href="https://doi.org/10.1002/ece3.7619">https://doi.org/10.1002/ece3.7619</a></p>
<p>Pfeffer, S. E., Spitzer, R., Allen, A. M., Hofmeester, T. R., Ericsson, G., Widemo, F., Singh, N. J., &amp; Cromsigt, J. P. G. M. (2018). Pictures or pellets? Comparing camera trapping and dung counts as methods for estimating population densities of ungulates. <em>Remote Sensing in Ecology and Conservation, 4</em>(2), 173‚Äì183. <a class="reference external" href="https://doi.org/10.1002/rse2.67">https://doi.org/10.1002/rse2.67</a></p>
<p>Rowcliffe, J. M., Field, J., Turvey, S. T., &amp; Carbone, C. (2008). Estimating animal Density using camera traps without the need for individual recognition. <em>Journal of Applied Ecology</em>, <em>45</em>(4), 1228‚Äì1236. <a class="reference external" href="https://doi.org/10.1111/j.1365-2664.2008.01473.x">https://doi.org/10.1111/j.1365-2664.2008.01473.x</a></p>
<p>Rowcliffe, J. M., Jansen, P. A., Kays, R., Kranstauber, B., &amp; Carbone, C. (2016). Wildlife speed cameras: measuring animal travel speed and day range using camera traps. <em>Remote Sensing in Ecology and Conservation, 2</em>, 84‚Äì94. <a class="reference external" href="https://doi.org/10.1002/rse2.17">https://doi.org/10.1002/rse2.17</a></p>
<p>Schaus, J., Uzal, A., Gentle, L. K., Baker, P. J., Bearman‚ÄêBrown, L., Bullion, S., Gazzard, A., Lockwood, H., North, A., Reader, T., Scott, D. M., Sutherland, C. S., &amp; Yarnell, R. W. (2020). Application of the Random Encounter Model in citizen science projects to monitor animal densities. <em>Remote Sensing in Ecology and Conservation, 6</em>(4), 514‚Äì528. <a class="reference external" href="https://doi.org/10.1002/rse2.153">https://doi.org/10.1002/rse2.153</a></p>
<p>Williams, B. K., Nichols, J. D., &amp; Conroy, M. J. (2002). <em>Analysis and Management of Animal Populations: Modeling, Estimation, and Decision Making</em>. Book, Whole. San Diego: Academic Press. <a class="reference external" href="https://go.exlibris.link/qSfqP9dC">https://go.exlibris.link/qSfqP9dC</a></p>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              
              
              
              
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>