
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Capture-recapture (CR) / Capture-mark-recapture (CMR) &#8212; Remote Camera Decision Support Tool - Concept Library</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy.css?v=7a364cf7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=cf5192f4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/03_10_mod_cr_cmr';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="capture-recapture-cr-capture-mark-recapture-cmr">
<span id="i-mod-cr-cmr"></span><h1>Capture-recapture (CR) / Capture-mark-recapture (CMR)<a class="headerlink" href="#capture-recapture-cr-capture-mark-recapture-cmr" title="Link to this heading">#</a></h1>
<p><strong>Capture-recapture (CR) model */ Capture-mark-recapture (CMR) model (Karanth, 1995; Karanth &amp; Nichols, 1998)</strong>: A method of estimating the abundance or <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> of marked populations using the number of animals detected and the likelihood animals will be detected (detection probability). CR (Karanth, 1995; Karanth &amp; Nichols, 1998) can be used to estimate vital rates where all newly detected unmarked animals become marked and are distinguishable in future (Efford, 2022). Spatially explicit capture-recapture (SECR; Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008) models have largely replaced CR and CMR models and provide more accurate <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> estimates (Blanc et al., 2013, Obbard et al., 2010, Sollmann et al., 2011).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Assumptions, Pros, Cons</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Assumptions</div>
<ul class="simple">
<li><p class="sd-card-text">Demographic closure (i.e., no births or deaths) (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Geographic closure (i.e., no immigration or emigration) (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">All individuals have at least some probability of being detected (Rovero et al., 2013)</p></li>
<li><p class="sd-card-text">Sampled area encompasses the full extent of individuals‚Äô movements (Karanth &amp; Nichols, 1998; Rovero et al., 2013)</p></li>
<li><p class="sd-card-text">Activity centres are randomly dispersed (Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Activity centres are stationary (Clarke et al., 2023)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Pros</div>
<ul class="simple">
<li><p class="sd-card-text">May be used as a relative abundance index that controls for imperfect detection (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Easy-to-use software exists to implement (e.g., CAPTURE)Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Can use the robust design with ‚Äòopen‚Äô models to obtain recruitment and survival rate estimates (Wearn &amp; Glover-Kapfer, 2017)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Cons</div>
<ul class="simple">
<li><p class="sd-card-text">Requires that individuals are distinguishable (Wearn &amp; Glover-Kapfer, 2017). However, CR (Sollmann, 2018; Rovero et al., 2013; Karanth &amp; Nichols, 1998) has also been used to estimate abundance of species that lack natural markers but that have phenotypic and*/or environment-induced characteristics (Noss et al., 2003; Kelly et al., 2008; Rovero et al., 2013)</p></li>
<li><p class="sd-card-text">When the sample size is large enough to reliably estimate <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> with CR, (Karanth, 1995; Karanth &amp; Nichols, 1998) individuals are unlikely to have a unique marker (Noss et al., 2003; Kelly et al., 2008; Rovero et al., 2013)</p></li>
<li><p class="sd-card-text">Dependent on the surveyed area, which is difficult to track and calculate (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Requires a minimum number of captures and recaptures (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Relatively stringent requirements for study design (e.g., no ‚Äòholes‚Äô in the trapping grid) (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text">Geographic closure at the plot level, which is often unrealistic (Wearn &amp; Glover-Kapfer, 2017) has also been used to estimate abundance of species that lack natural markers but that have phenotypic and*/or environment-induced characteristics (Noss et al., 2003; Kelly et al., 2008; Rovero et al., 2013)</p></li>
<li><p class="sd-card-text">Assumes a specific relationship between abundance and detection (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text"><a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">Density</span></a> cannot be explicitly estimated because the true area animals occupy is never measured (only approximated) (Chandler &amp; Royle, 2013)</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</details><div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Overview</label><div class="sd-tab-content docutils">
<p>This section will be available soon! In the meantime, check out the information in the other tabs!</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/00_coming_soon.png"><img alt="../_images/00_coming_soon.png" src="../_images/00_coming_soon.png" style="width: 300px;" /></a>
</figure>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
In-depth</label><div class="sd-tab-content docutils">
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>This content was adapted from</strong>: The Density Handbook, ‚Äú<a class="reference external" href="https://www.researchgate.net/publication/368601884_Using_Camera_Traps_to_Estimate_Medium_and_Large_Mammal_Density_Comparison_of_Methods_and_Recommendations_for_Wildlife_Managers">Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</a>‚Äù (Clarke et al., 2024)</p>
</div>
<p>Of all the modelling frameworks discussed in this document, capture-recapture (CR) also called capture-mark-recapture or mark-recapture ‚Äì is perhaps the most wellknown. Since the 19th century, CR has been used to measure population size by  capturing, marking, releasing and recapturing individuals (Le Cren, 1965, Otis et al., 1978). For species or populations that are challenging to physically trap and mark, CR  can also be applied to DNA, acoustic and camera trap data (Royle et al., 2014). Here,  we will discuss camera trap CR.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_fig11_clipped.png"><img alt="../_images/clarke_et_al_2023_fig11_clipped.png" src="../_images/clarke_et_al_2023_fig11_clipped.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-text"><strong>Clarke et al. (2023) ‚Äì Fig. 11</strong> Adapted from Royle (2020). A detection history matrix for an example population. For each individual (1 through <em>ùëõ</em>) during each sampling occasion (1 through <em>ùêæ</em>), a value of 1 is assigned if that individual was detected at a camera trap and a value of 0 is assigned if it was not detected at a camera trap. Note that we do not detect individuals <em>ùëõ</em> + 1, <em>ùëõ</em> + 2‚Ä¶<em>ùëÅ</em> (0s for every sampling occasion), but they are still present and able to be detected.</span><a class="headerlink" href="#id1" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>To estimate density using camera trap CR, we must first estimate population size <em>ùëÅ</em>. CR models use individuals‚Äô detection histories ‚Äì that is, the record of when each individual was photographed or not photographed (i.e., (re)captured or not (re)captured) ‚Äì to solve for <em>ùëÅ</em> (Figure 3; Royle, 2020). Population-level detection histories look like a matrix of 1s and 0s, where 1s signify that an individual was captured during a given sampling occasion <em>ùëò</em>, and 0s signify that the individual was not captured during that occasion (Royle, 2020, Royle et al., 2014). The number of individuals photographed at least once over the course of the study (i.e., the count of animals captured) is <em>ùëõ</em>.</p>
<p>Importantly, the count of animals is not the same as the size of the population (i.e., <em>ùëõ</em> ‚â† <em>ùëÅ</em>). Some individuals will never be photographed during a study, even though they are present and able to be detected (i.e., they are in <em>ùëÅ</em> but not in <em>ùëõ</em>; Royle, 2020). Using the matrix of detection histories, we must therefore calculate the likelihood animals will be detected by an array of camera traps ‚Äì that is, detection probability <em>p</em> (Royle, 2020).</p>
<p>Taking this information together, we can calculate population size <em>ùëÅ</em> as:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_cr1.png"><img alt="../_images/clarke_et_al_2023_eqn_cr1.png" src="../_images/clarke_et_al_2023_eqn_cr1.png" style="width: 130px;" /></a>
</figure>
<p>which is often referred to as the canonical estimator of population size (Royle, 2020). Population size <em>ùëÅ</em> can then be divided by an estimate of the area of the sampling frame <em>ùê¥</em> to obtain density.</p>
<p>CR models have important limitations ‚Äì notably that they do not consider the spatial configuration of camera traps or the spatial pattern of animal detections. This gives rise to two major issues:</p>
<ol class="arabic simple">
<li><p>The sampling frame <em>ùê¥</em> is not known (Chandler &amp; Royle, 2013). In other words: the true area animals occupy is never measured, only approximated using adhoc approaches (e.g., using a buffer strip around the trap array; Rich et al., 2014, Sollmann et al., 2018). Consequently, density cannot be calculated explicitly (Chandler &amp; Royle, 2013), and CR-derived density estimates are somewhat arbitrary and difficult to compare across studies (Green et al., 2020, Royle et al., 2014, Sollmann et al., 2018).</p></li>
<li><p>Detection probability is assumed to be the same across all individuals and sampling occasions, even though the likelihood a given individual is detected at a given camera trap will change with its proximity to that trap. An animal that occupies territory far away from a trap is less likely to be detected there than one that lives nearby, for example (Morin et al., 2022).</p></li>
</ol>
<p>The standard CR model has largely been phased out with the advent of spatially-explicit CR models (see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_11_mod_scr_secr.html"><span>Spatial capture-recapture (SCR) / Spatially explicit capture recapture (SECR)</span></a>); Burton et al., 2015, Sollmann et al., 2018), which address the shortcomings of CR and have been shown to produce more accurate density estimates (e.g., Blanc et al., 2013, Obbard et al., 2010, Sollmann et al., 2011).</p>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
Visual resources</label><div class="sd-tab-content docutils">
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_fig11_clipped.png" class="img-grid" src="../_images/clarke_et_al_2023_fig11_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Clarke et al. (2023) ‚Äì Fig. 3</strong> Adapted from Royle (2020). A detection history matrix for an example population.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-kebab-horizontal no-title" viewBox="0 0 24 24" aria-hidden="true"><path d="M20 14a2 2 0 1 1-.001-3.999A2 2 0 0 1 20 14ZM6 12a2 2 0 1 1-3.999.001A2 2 0 0 1 6 12Zm8 0a2 2 0 1 1-3.999.001A2 2 0 0 1 14 12Z"></path></svg></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">For each individual (1 through <em>ùëõ</em>) during each sampling occasion (1 through <em>ùêæ</em>), a value of 1 is assigned if that individual was detected at a camera trap and a value of 0 is assigned if it was not detected at a camera trap. Note that we do not detect individuals <em>ùëõ</em> + 1, <em>ùëõ</em> + 2‚Ä¶<em>ùëÅ</em> (0s for every sampling occasion), but they are still present and able to be detected.</p>
</div>
</details></div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_cr1.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_cr1.png" />
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-3">
Shiny apps/Widgets</label><div class="sd-tab-content docutils">
<p>Check back in the future!</p>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-4">
Analytical tools &amp; resources</label><div class="sd-tab-content docutils">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Type</p></th>
<th class="head text-left"><p>Name</p></th>
<th class="head text-left"><p>Note</p></th>
<th class="head text-left"><p>URL</p></th>
<th class="head text-left"><p>Reference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>resource1_type</p></td>
<td class="text-left"><p>resource1_name</p></td>
<td class="text-left"><p>resource1_note</p></td>
<td class="text-left"><p>resource1_url</p></td>
<td class="text-left"><p>ref_bib_resource1_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource2_type</p></td>
<td class="text-left"><p>resource2_name</p></td>
<td class="text-left"><p>resource2_note</p></td>
<td class="text-left"><p>resource2_url</p></td>
<td class="text-left"><p>ref_bib_resource2_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource3_type</p></td>
<td class="text-left"><p>resource3_name</p></td>
<td class="text-left"><p>resource3_note</p></td>
<td class="text-left"><p>resource3_url</p></td>
<td class="text-left"><p>ref_bib_resource3_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource4_type</p></td>
<td class="text-left"><p>resource4_name</p></td>
<td class="text-left"><p>resource4_note</p></td>
<td class="text-left"><p>resource4_url</p></td>
<td class="text-left"><p>ref_bib_resource4_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource5_type</p></td>
<td class="text-left"><p>resource5_name</p></td>
<td class="text-left"><p>resource5_note</p></td>
<td class="text-left"><p>resource5_url</p></td>
<td class="text-left"><p>ref_bib_resource5_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource6_type</p></td>
<td class="text-left"><p>resource6_name</p></td>
<td class="text-left"><p>resource6_note</p></td>
<td class="text-left"><p>resource6_url</p></td>
<td class="text-left"><p>ref_bib_resource6_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource7_type</p></td>
<td class="text-left"><p>resource7_name</p></td>
<td class="text-left"><p>resource7_note</p></td>
<td class="text-left"><p>resource7_url</p></td>
<td class="text-left"><p>ref_bib_resource7_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource8_type</p></td>
<td class="text-left"><p>resource8_name</p></td>
<td class="text-left"><p>resource8_note</p></td>
<td class="text-left"><p>resource8_url</p></td>
<td class="text-left"><p>ref_bib_resource8_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource9_type</p></td>
<td class="text-left"><p>resource9_name</p></td>
<td class="text-left"><p>resource9_note</p></td>
<td class="text-left"><p>resource9_url</p></td>
<td class="text-left"><p>ref_bib_resource9_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource10_type</p></td>
<td class="text-left"><p>resource10_name</p></td>
<td class="text-left"><p>resource10_note</p></td>
<td class="text-left"><p>resource10_url</p></td>
<td class="text-left"><p>ref_bib_resource10_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource11_type</p></td>
<td class="text-left"><p>resource11_name</p></td>
<td class="text-left"><p>resource11_note</p></td>
<td class="text-left"><p>resource11_url</p></td>
<td class="text-left"><p>ref_bib_resource11_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource12_type</p></td>
<td class="text-left"><p>resource12_name</p></td>
<td class="text-left"><p>resource12_note</p></td>
<td class="text-left"><p>resource12_url</p></td>
<td class="text-left"><p>ref_bib_resource12_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource13_type</p></td>
<td class="text-left"><p>resource13_name</p></td>
<td class="text-left"><p>resource13_note</p></td>
<td class="text-left"><p>resource13_url</p></td>
<td class="text-left"><p>ref_bib_resource13_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource14_type</p></td>
<td class="text-left"><p>resource14_name</p></td>
<td class="text-left"><p>resource14_note</p></td>
<td class="text-left"><p>resource14_url</p></td>
<td class="text-left"><p>ref_bib_resource14_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource15_type</p></td>
<td class="text-left"><p>resource15_name</p></td>
<td class="text-left"><p>resource15_note</p></td>
<td class="text-left"><p>resource15_url</p></td>
<td class="text-left"><p>ref_bib_resource15_ref_id</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-5">
References</label><div class="sd-tab-content docutils">
<p>Blanc, L., Marboutin, E., Gatti, S., &amp; Gimenez, O. (2013). Abundance of Rare and Elusive Species: Empirical Investigation of Closed versus Spatially Explicit Capture-Recapture Models with Lynx as a Case Study. <em>Journal of Wildlife Management, 77</em>(2), 372‚Äì78. <a class="reference external" href="https://doi.org/10.1002/jwmg.453">https://doi.org/10.1002/jwmg.453</a></p>
<p>Burton, A. C., Neilson, E., Moreira, D., Ladle, A., Steenweg, R., Fisher, J. T., Bayne, E., Boutin, S., &amp; Stephens, P. (2015). Camera trap Trapping: A Review and Recommendations for Linking Surveys to Ecological Processes. <em>Journal of Applied Ecology</em>, <em>52</em>(3), 675‚Äì685. <a class="reference external" href="https://doi.org/10.1111/1365-2664.12432">https://doi.org/10.1111/1365-2664.12432</a></p>
<p>Chandler, R. B., &amp; Royle, J. A. (2013). Spatially explicit models for inference about Density in unmarked or partially marked populations. <em>The Annals of Applied Statistics, 7</em>(2), 936‚Äì954. <a class="reference external" href="https://doi.org/10.1214/12-aoas610">https://doi.org/10.1214/12-aoas610</a></p>
<p>Clarke, J., Bohm, H., Burton, C., Constantinou, A. (2023). <em>Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</em>. <a class="reference external" href="https://doi.org/10.13140/RG.2.2.18364.72320">https://doi.org/10.13140/RG.2.2.18364.72320</a></p>
<p>Green, A. M., Chynoweth, M. W., &amp; ≈ûekercioƒülu, √á. H. (2020). Spatially Explicit Capture-Recapture Through Camera Trapping: A Review of Benchmark Analyses for Wildlife Density Estimation. <em>Frontiers in Ecology and Evolution</em>, 8, Article 563477. <a class="reference external" href="https://doi.org/10.3389/fevo.2020.563477">https://doi.org/10.3389/fevo.2020.563477</a></p>
<p>Le Cren, E. D. (1965). A Note on the History of Mark-Recapture Population Estimates. <em>The Journal of Animal Ecology, 34</em>(2),453‚Äì54. <a class="reference external" href="https://doi.org/10.2307/2661">https://doi.org/10.2307/2661</a></p>
<p>Obbard, M. E., Howe, E. J., &amp; Kyle, C. J. (2010). Empirical Comparison of Density Estimators for Large Carnivores. <em>Journal of Applied Ecology</em>, 47(1), 76‚Äì84. <a class="reference external" href="https://doi.org/10.1111/j.1365-2664.2009.01758.x">https://doi.org/10.1111/j.1365-2664.2009.01758.x</a></p>
<p>Otis, D. L., Burnham, K. P., White, G. C.. &amp; Anderson, D. R. (1978). Statistical Inference from Capture Data on Closed Animal Populations. <em>Wildlife Monographs, 62</em>, 3‚Äì135. <a class="reference external" href="https://pubs.usgs.gov/publication/70119899">https://pubs.usgs.gov/publication/70119899</a></p>
<p>Morin, D. J., Boulanger, J., Bischof, R., Lee, D. C., Ngoprasert, D., Fuller, A. K., McLellan, B., Steinmetz, R., Sharma, S., Garshelis, D., Gopalaswamy, A., Nawaz, M. A., &amp; Karanth, U. (2022).comparison of methods for estimating Density and population trends for low-Density Asian bears. <em>Global Ecology and Conservation, 35</em>, e02058 <a class="reference external" href="https://doi.org/10.1016/j.gecco.2022.e02058">https://doi.org/10.1016/j.gecco.2022.e02058</a></p>
<p>Rich, L. N., Kelly, M. J., Sollmann, R., Noss, A. J., Maffei, L., Arispe, R. L., Paviolo, A., De Angelo, C. D., Di Blanco, Y. E., &amp; Di Bitetti, M. S. (2014).comparing capture-recapture, mark-resight, and spatial mark-resight models for estimating puma densities via camera traps. <em>Journal of Mammalogy, 95</em>(2), 382‚Äì391. <a class="reference external" href="https://doi.org/10.1644/13-mamm-a-126">https://doi.org/10.1644/13-mamm-a-126</a></p>
<p>Royle, J. A., Converse, S. J., &amp; Freckleton, R. (2014). Hierarchical spatial capture-recapture models: modelling population Density in stratified populations. <em>Methods in Ecology and Evolution, 5</em>(1), 37-43. <a class="reference external" href="https://doi.org/10.1111/2041-210x.12135">https://doi.org/10.1111/2041-210x.12135</a></p>
<p>Royle, A. J. (2020, Oct 26) <em>Introduction to Spatial Capture-Recapture. oSCR Package</em>, [Video]. YouTube. <a class="reference external" href="https://www.youtube.com/watch?v=yRRDi07FtPg">https://www.youtube.com/watch?v=yRRDi07FtPg</a></p>
<p>Sollmann, R. (2018). A gentle introduction to camera‚Äêtrap data analysis. <em>African Journal of Ecology,</em> 56, 740‚Äì749. <a class="reference external" href="https://doi.org/10.1111/aje.12557">https://doi.org/10.1111/aje.12557</a></p>
<p>Sollmann, R., Furtado, M. M., Gardner, B., Hofer, H., J√°como, A. T. A., T√¥rres, N. M., &amp; Silveira, L. (2011). Improving Density Estimates for Elusive Carnivores: Accounting for Sex-Specific Detection and Movements Using Spatial Capture‚ÄìRecapture Models for Jaguars in Central Brazil. <em>Biological Conservation</em>, 144(3), 1017‚Äì24. <a class="reference external" href="https://doi.org/10.1016/j.biocon.2010.12.011">https://doi.org/10.1016/j.biocon.2010.12.011</a></p>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              
              
              
              
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>