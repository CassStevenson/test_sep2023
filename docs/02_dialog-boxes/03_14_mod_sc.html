
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Spatial count (SC) model / Unmarked spatial capture-recapture &#8212; Remote Camera Decision Support Tool - Concept Library</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy.css?v=7a364cf7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=6423beaa" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/03_14_mod_sc';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="spatial-count-sc-model-unmarked-spatial-capture-recapture">
<span id="i-mod-sc"></span><h1>Spatial count (SC) model / Unmarked spatial capture-recapture<a class="headerlink" href="#spatial-count-sc-model-unmarked-spatial-capture-recapture" title="Link to this heading">#</a></h1>
<p><strong>Spatial count (SC) model / Unmarked spatial capture-recapture (Chandler &amp; Royle, 2013)</strong>: A method used to estimate the <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> of unmarked populations; similar to SECR (Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008; Royle et al., 2009); however, SC models account for individuals’ unknown identities using the spatial pattern of detections (Chandler &amp; Royle, 2013; Sun et al., 2022). SC uses trap-specific counts to estimate the location and number of activity centres to estimate <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a>.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Assumptions, Pros, Cons</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Assumptions</div>
<ul class="simple">
<li><p class="sd-card-text">Camera locations are close enough together that animals are detected at multiple cameras (Chandler &amp; Royle, 2013; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Demographic closure (i.e., no births or deaths) (Chandler &amp; Royle, 2013; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Geographic closure (i.e., no immigration or emigration) (Chandler &amp; Royle, 2013; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Detections are <a class="reference internal" href="09_glossary.html#independent-detections"><span class="std std-ref">independent</span></a> (Chandler &amp; Royle, 2013; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Animals’ activity centres are randomly dispersed (Chandler &amp; Royle, 2013; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Animals’ activity centres are stationary (Chandler &amp; Royle, 2013; Clarke et al., 2023)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Pros</div>
<ul class="simple">
<li><p class="sd-card-text">Does not require individual identification (Clarke et al., 2023)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Cons</div>
<ul class="simple">
<li><p class="sd-card-text">Produces imprecise estimates even under ideal circumstances unless supplemented with auxiliary data (e.g., telemetry) (Doran-Myers, 2018; Chandler &amp; Royle, 2013; Sollmann et al., 2013a; Sollmann et al., 2013b)</p></li>
<li><p class="sd-card-text">Precision decreases with an increasing number of individuals detected at a camera’ (Morin et al., 2022) (as overlap of individuals’ home ranges increases) (Augustine et al., 2019; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Not appropriate for low <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> or elusive species when recaptures too few to confidently infer the number and location of activity centres’ (Clarke et al., 2023; Burgar et al., 2018)</p></li>
<li><p class="sd-card-text">Not appropriate for high-<a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> populations with evenly spaced activity centres (camera[-specific] counts will be too similar and impair activity centre inference)’ (Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Ill-suited to populations that exhibit group-travelling behaviour’ (Sun et al., 2022; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Study design (camera arrangement) can dramatically affect the accuracy and precision of <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> estimates’ (Clarke et al., 2023; (Undefined, 2018))</p></li>
<li><p class="sd-card-text">Cameras must be close enough that animals are detected at multiple camera locations (may be challenging at large scales as many cameras are needed)’ (Chandler &amp; Royle, 2013; Clarke et al., 2023)</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</details><div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Overview</label><div class="sd-tab-content docutils">
<p>This section will be available soon! In the meantime, check out the information in the other tabs!</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/00_coming_soon.png"><img alt="../_images/00_coming_soon.png" src="../_images/00_coming_soon.png" style="width: 300px;" /></a>
</figure>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
In-depth</label><div class="sd-tab-content docutils">
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>This content was adapted from</strong>: The Density Handbook, “<a class="reference external" href="https://www.researchgate.net/publication/368601884_Using_Camera_Traps_to_Estimate_Medium_and_Large_Mammal_Density_Comparison_of_Methods_and_Recommendations_for_Wildlife_Managers">Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</a>” (Clarke et al., 2024)</p>
</div>
<p>A spatial count (SC) model is essentially a spatial capture-recapture (SCR; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_11_mod_scr_secr.html"><span>Spatial capture-recapture (SCR) / Spatially explicit capture recapture (SECR)</span></a>) model with an extension to account for unmarked animals’ unknown identities (Royle et al., 2014). SC, then, is formulated in much the same way as SCR: populations are treated as collections of individual activity (or home range) centres, and spatial detection data is used to infer the number and locations of these activity centres (see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_11_mod_scr_secr.html"><span>Spatial capture-recapture (SCR) / Spatially explicit capture recapture (SECR)</span></a>). Instead of identifying animals and constructing individual detection histories (i.e., each individual’s spatial pattern of detections), however, SC uses trap-specific counts (i.e., the tally of animal detections at each trap of known location) and the correlation structure among trapspecific counts to estimate the number and location of activity centres (Royle et al., 2014, Sun et al., 2022).</p>
<p>Like SCR, an SC model is composed of a spatial process model and an observation model. The spatial process model, which describes how activity centres are distributed across the landscape, is a homogeneous point-process model – a completely random pattern of points in space (Baddeley, no date; Royle, 2016). The observation model, which describes where individuals are detected on the landscape, is constructed as if we know each individual’s detection history and the size of the population (Chandler &amp; Royle, 2013). As Royle et al. (2014) put it: “[SC] is formulated in terms of the data we wish we had, i.e., the typical [detection] history data observed in [SCR] studies of marked animals.” We can construct an SC model in this way because trap-specific counts of animals arise from those animals’ detection histories; in other words, counts are a simplified version of the data that would have been collected, had individuals been identifiable (Chandler &amp; Royle, 2013, Sun et al., 2022).</p>
<p>To relate trap-specific counts to detection histories, we use the equation:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_sc1.png"><img alt="../_images/clarke_et_al_2023_eqn_sc1.png" src="../_images/clarke_et_al_2023_eqn_sc1.png" style="width: 80px;" /></a>
</figure>
<p>where <em>n<sub>𝑗𝑘</sub></em> is the count of animals at sampling location <em>𝑗</em> and during sampling period <em>𝑘</em>; <em>𝑁</em> is population size; and <em>𝑦<sub>𝑖𝑗𝑘</sub></em> is individual 𝑖’s detection history at sampling location <em>𝑗</em> and during sampling period <em>𝑘</em> (Royle et al., 2014). So, the trap- and period-specific count <em>n<sub>𝑗𝑘</sub></em>
– the information we gather for SC – is the same as the sum of every individual’s encounter history at that trap – the information we gather for SCR (Royle et al., 2014).</p>
<p>To approximate population size, we take a data augmentation approach. Population size <em>𝑁</em> is treated as a subset of some larger, hypothetical population of size <em>𝑀</em> (the “augmented” population; Royle &amp; Dorazio, 2012), such that:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_sc2.png"><img alt="../_images/clarke_et_al_2023_eqn_sc2.png" src="../_images/clarke_et_al_2023_eqn_sc2.png" style="width: 80px;" /></a>
</figure>
<p>where <em>𝑀</em> ≫ <em>𝑁</em> and <em>𝜔<sub>𝑖</sub></em> is the probability of existence of individual <em>𝑖</em> within population <em>𝑁</em> (Chandler &amp; Royle, 2013, Sun et al., 2022). <em>𝜔<sub>𝑖</sub></em> is Bernoulli distributed – an animal can be present (i.e., <em>𝜔<sub>𝑖</sub></em> = 1) or absent (i.e., <em>𝜔<sub>𝑖</sub></em> = 0) – and depends on the number of detections at traps and the distance between traps and individuals’ activity centres (Chandler &amp; Royle, 2013, Sun et al., 2022).</p>
<p>Note that, for SC, a “trap” is simply a tool or method for collecting count data. Trap types include hair snags, track plates, acoustic recording devices, human point-count observers and camera traps (Chandler &amp; Royle, 2013, Royle et al., 2014). We will refer to camera traps for the remainder of this section.</p>
<p>The aim of SC sampling design is to infer the number and location of activity centres by inducing correlation (i.e., linear relation) between the number and location of detections (Burgar et al., 2019, Chandler &amp; Royle, 2013, Sollmann et al., 2018, Sun et al., 2022). To this end, camera traps must be deployed close enough together that individuals will be detected at multiple locations (Chandler &amp; Royle, 2013). Grid or clustered designs may be best (Burgar et al., 2019, Clarke, 2019, Sun et al., 2014).</p>
<h2 class="rubric" id="simulations-and-field-experiments">Simulations and Field Experiments</h2>
<p>The relatively few studies that have tested SC models suggest that they tend to produce fairly accurate but imprecise density estimates.</p>
<ul class="simple">
<li><p>A study on fishers showed that, compared to genetic SCR, SC underestimated density and estimates were less precise (Burgar et al., 2018).</p></li>
<li><p>Evans and Rittenhouse (2018) found that SC yielded accurate but less precise estimates of black bear density than camera trap SCR.</p></li>
<li><p>Another study compared estimates of caribou density from SC with estimates from the spatial partial identity model (SPIM; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_15_mod_catspim.html"><span>Spatial Partial Identity Model (Categorical SPIM; catSPIM)</span></a>and <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_16_mod_2flankspim.html"><span>Spatial Partial Identity Model (2-flank SPIM)</span></a>). In this system, SC likely underestimated density compared with SPIM – perhaps because the model interpreted captures of many individuals as recaptures of a few individuals – and was less precise and more variable year-toyear (Sun et al., 2022).</p></li>
<li><p>SC was used to estimate the densities of caribou, moose, wolf, coyote and black bear populations in the oil sands region of Alberta (Burgar et al., 2019). Estimates for all species were imprecise; some had confidence intervals with upper and lower bounds that differed more than 10-fold. The authors note, however, that other density estimation methods used in the region (e.g., aerial surveys) are not more precise than SC (Burgar et al., 2019). The researchers also simulated their data, finding that SC tended to underestimate density when the number of captures and spatial recaptures (i.e., spatially-correlated detections between cameras) were low.
Box 1. The unmarked models that follow estimate density within the collective viewshed area (i.e., the combined fields-of-view of all cameras in a network) and assume that this estimate applies to the larger study area (Gilbert et al., 2020). This is in contrast to spatial capture-recapture (SCR; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_11_mod_scr_secr.html"><span>Spatial capture-recapture (SCR) / Spatially explicit capture recapture (SECR)</span></a>) models and derivatives – including spatial count (SC; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_14_mod_sc.html"><span>Spatial count</span></a>), spatial mark-resight (SMR; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_13_mod_smr.html"><span>Spatial mark-resight</span></a>) and the spatial partial identity model (SPIM; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_15_mod_catspim.html"><span>Spatial Partial Identity Model (Categorical SPIM; catSPIM)</span></a>and <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_16_mod_2flankspim.html"><span>Spatial Partial Identity Model (2-flank SPIM)</span></a>) – which estimate density over a defined area.</p></li>
</ul>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
Visual resources</label><div class="sd-tab-content docutils">
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
ref_intext_figure1_ref_id</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_sc1.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_sc1.png" />
</figure>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
ref_intext_figure2_ref_id</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_sc2.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_sc2.png" />
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-3">
Shiny apps/Widgets</label><div class="sd-tab-content docutils">
<p>Check back in the future!</p>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-4">
Analytical tools &amp; Resources</label><div class="sd-tab-content docutils">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Type</p></th>
<th class="head text-left"><p>Name</p></th>
<th class="head text-left"><p>Note</p></th>
<th class="head text-left"><p>URL</p></th>
<th class="head text-left"><p>Reference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>resource1_type</p></td>
<td class="text-left"><p>resource1_name</p></td>
<td class="text-left"><p>resource1_note</p></td>
<td class="text-left"><p>resource1_url</p></td>
<td class="text-left"><p>ref_bib_resource1_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource2_type</p></td>
<td class="text-left"><p>resource2_name</p></td>
<td class="text-left"><p>resource2_note</p></td>
<td class="text-left"><p>resource2_url</p></td>
<td class="text-left"><p>ref_bib_resource2_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource3_type</p></td>
<td class="text-left"><p>resource3_name</p></td>
<td class="text-left"><p>resource3_note</p></td>
<td class="text-left"><p>resource3_url</p></td>
<td class="text-left"><p>ref_bib_resource3_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource4_type</p></td>
<td class="text-left"><p>resource4_name</p></td>
<td class="text-left"><p>resource4_note</p></td>
<td class="text-left"><p>resource4_url</p></td>
<td class="text-left"><p>ref_bib_resource4_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource5_type</p></td>
<td class="text-left"><p>resource5_name</p></td>
<td class="text-left"><p>resource5_note</p></td>
<td class="text-left"><p>resource5_url</p></td>
<td class="text-left"><p>ref_bib_resource5_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource6_type</p></td>
<td class="text-left"><p>resource6_name</p></td>
<td class="text-left"><p>resource6_note</p></td>
<td class="text-left"><p>resource6_url</p></td>
<td class="text-left"><p>ref_bib_resource6_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource7_type</p></td>
<td class="text-left"><p>resource7_name</p></td>
<td class="text-left"><p>resource7_note</p></td>
<td class="text-left"><p>resource7_url</p></td>
<td class="text-left"><p>ref_bib_resource7_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource8_type</p></td>
<td class="text-left"><p>resource8_name</p></td>
<td class="text-left"><p>resource8_note</p></td>
<td class="text-left"><p>resource8_url</p></td>
<td class="text-left"><p>ref_bib_resource8_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource9_type</p></td>
<td class="text-left"><p>resource9_name</p></td>
<td class="text-left"><p>resource9_note</p></td>
<td class="text-left"><p>resource9_url</p></td>
<td class="text-left"><p>ref_bib_resource9_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource10_type</p></td>
<td class="text-left"><p>resource10_name</p></td>
<td class="text-left"><p>resource10_note</p></td>
<td class="text-left"><p>resource10_url</p></td>
<td class="text-left"><p>ref_bib_resource10_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource11_type</p></td>
<td class="text-left"><p>resource11_name</p></td>
<td class="text-left"><p>resource11_note</p></td>
<td class="text-left"><p>resource11_url</p></td>
<td class="text-left"><p>ref_bib_resource11_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource12_type</p></td>
<td class="text-left"><p>resource12_name</p></td>
<td class="text-left"><p>resource12_note</p></td>
<td class="text-left"><p>resource12_url</p></td>
<td class="text-left"><p>ref_bib_resource12_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource13_type</p></td>
<td class="text-left"><p>resource13_name</p></td>
<td class="text-left"><p>resource13_note</p></td>
<td class="text-left"><p>resource13_url</p></td>
<td class="text-left"><p>ref_bib_resource13_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource14_type</p></td>
<td class="text-left"><p>resource14_name</p></td>
<td class="text-left"><p>resource14_note</p></td>
<td class="text-left"><p>resource14_url</p></td>
<td class="text-left"><p>ref_bib_resource14_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource15_type</p></td>
<td class="text-left"><p>resource15_name</p></td>
<td class="text-left"><p>resource15_note</p></td>
<td class="text-left"><p>resource15_url</p></td>
<td class="text-left"><p>ref_bib_resource15_ref_id</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-5">
References</label><div class="sd-tab-content docutils">
<p>Burgar, J. M., Stewart, F. E. C., Volpe, J. P., Fisher, J. T., &amp; Burton, A. C. (2018). Estimating Density for species conservation: comparing camera trap spatial count models to genetic spatial capture-recapture models. <em>Global Ecology and Conservation</em>, <em>15</em>, Article e00411. <a class="reference external" href="https://doi.org/10.1016/j.gecco.2018.e00411">https://doi.org/10.1016/j.gecco.2018.e00411</a></p>
<p>Burgar, J. M., Burton, A. C., &amp; Fisher, J. T. (2019). The importance of considering multiple interacting species for conservation of species at risk. <em>Conservation Biology, 33</em>(3), 709–715. <a class="reference external" href="https://doi.org/10.1111/cobi.13233">https://doi.org/10.1111/cobi.13233</a></p>
<p>Chandler, R. B., &amp; Royle, J. A. (2013). Spatially explicit models for inference about Density in unmarked or partially marked populations. <em>The Annals of Applied Statistics, 7</em>(2), 936–954. <a class="reference external" href="https://doi.org/10.1214/12-aoas610">https://doi.org/10.1214/12-aoas610</a></p>
<p>Clarke, J. D. (2019).comparing Clustered Sampling Designs for Spatially Explicit Estimation of Population Density. <em>Population Ecology, 61</em>, 93–101. <a class="reference external" href="https://doi.org/10.1002/1438-390X.1011">https://doi.org/10.1002/1438-390X.1011</a></p>
<p>Clarke, J., Bohm, H., Burton, C., Constantinou, A. (2023). <em>Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</em>. <a class="reference external" href="https://doi.org/10.13140/RG.2.2.18364.72320">https://doi.org/10.13140/RG.2.2.18364.72320</a></p>
<p>Evans, M. J. &amp; Rittenhouse, T. A. G. (2018). Evaluating Spatially Explicit Density Estimates of Unmarked Wildlife Detected by Remote Cameras. <em>The Journal of Applied Ecology 55</em>(6), 2565–74. <a class="reference external" href="https://doi.org/10.1111/1365-2664.13194">https://doi.org/10.1111/1365-2664.13194</a></p>
<p>Gilbert, N. A., Clare, J. D. J., Stenglein, J. L., &amp; Zuckerberg, B. (2020). Abundance Estimation of Unmarked Animals based on Camera-Trap Data. <em>Conservation Biology, 35</em>(1), 88-100. <a class="reference external" href="https://doi.org/10.1111/cobi.13517">https://doi.org/10.1111/cobi.13517</a></p>
<p>Royle, A. J. (2016, Oct 17). <em>‘Spatial Capture-Recapture Modelling.’ CompSustNet</em> [Video]. YouTube. <a class="reference external" href="https://www.youtube.com/watch?v=4HKFimATq9E">https://www.youtube.com/watch?v=4HKFimATq9E</a></p>
<p>Royle, J. A., &amp; Dorazio, R. M. (2012). Parameter-expanded data augmentation for Bayesian analysis of capture–recapture models. <em>Journal of Ornithology, 152</em>(S2), 521–537. <a class="reference external" href="https://doi.org/10.1007/s10336-010-0619-4">https://doi.org/10.1007/s10336-010-0619-4</a></p>
<p>Royle, J. A., Converse, S. J., &amp; Freckleton, R. (2014). Hierarchical spatial capture-recapture models: modelling population Density in stratified populations. <em>Methods in Ecology and Evolution, 5</em>(1), 37-43. <a class="reference external" href="https://doi.org/10.1111/2041-210x.12135">https://doi.org/10.1111/2041-210x.12135</a></p>
<p>Sun, C. C., Fuller, A. K., &amp; Royle., J. A. (2014). Trap Configuration and Spacing Influences Parameter Estimates in Spatial Capture-Recapture Models. <em>PLoS One, 9</em>(2): e88025. <a class="reference external" href="https://doi.org/10.1371/journal.pone.0088025">https://doi.org/10.1371/journal.pone.0088025</a></p>
<p>Sun, C., Burgar, J. M., Fisher, J. T., &amp; Burton, A. C. (2022). A Cautionary Tale Comparing Spatial Count and Partial Identity Models for Estimating Densities of Threatened and Unmarked Populations. <em>Global Ecology and Conservation, 38</em>, e02268. <a class="reference external" href="https://doi.org/10.1016/j.gecco.2022.e02268">https://doi.org/10.1016/j.gecco.2022.e02268</a></p>
<p>Sollmann, R. (2018). A gentle introduction to camera‐trap data analysis. <em>African Journal of Ecology,</em> 56, 740–749. <a class="reference external" href="https://doi.org/10.1111/aje.12557">https://doi.org/10.1111/aje.12557</a></p>
<p>Gilbert, N. A., Clare, J. D. J., Stenglein, J. L., &amp; Zuckerberg, B. (2020). Abundance Estimation of Unmarked Animals based on Camera-Trap Data. <em>Conservation Biology, 35</em>(1), 88-100. <a class="reference external" href="https://doi.org/10.1111/cobi.13517">https://doi.org/10.1111/cobi.13517</a></p>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              
              
              
              
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>