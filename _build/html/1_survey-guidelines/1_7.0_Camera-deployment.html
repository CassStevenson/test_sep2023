
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7.0 Camera deployment &#8212; Remote Camera Survey Guidelines - Guidelines for Western Canada</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=4b2c329f" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-C74BERTX94"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-C74BERTX94');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-C74BERTX94');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '1_survey-guidelines/1_7.0_Camera-deployment';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8.0 Data management and processing" href="1_8.0_Data-management-and-processing.html" />
    <link rel="prev" title="6.0 Study design" href="1_6.0_Study-design.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Remote Camera Survey Guidelines - Guidelines for Western Canada - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Remote Camera Survey Guidelines - Guidelines for Western Canada - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Remote Camera Survey Guidelines & AB Metadata Standards
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Remote Camera Survey Guidelines</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1_0.1_Citation-and-Info.html">Citation &amp; Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_0.2_Acknowledgments.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_0.3_TOC.html">Table of Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_0.4_List-Tables-Figures.html">List of Tables &amp; List of Figures</a></li>

<li class="toctree-l1"><a class="reference internal" href="1_1.0_Background.html">1.0 Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_2.0_Intended-Audience-and-How-to-use-this-document.html">2.0 Intended Audience and How to use this document</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_3.0_Design-hierarchy.html">3.0 Design hierarchy</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_4.0_Objectives.html">4.0 Objectives</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_5.0_Detection-probability.html">5.0 Detection probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_6.0_Study-design.html">6.0 Study design</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">7.0 Camera deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_8.0_Data-management-and-processing.html">8.0 Data management and processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_9.0_References.html">9.0 References</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_10.1_AppendixA-Tables.html">Appendix A - Tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html">Appendix A - Field Datasheets</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_11.0_AppendixB-FigureB1.html">Appendix B</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">AB Remote Camera Metadata Standards</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_0.1_Citation-and-Info.html">Citation &amp; Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_0.2_Preface.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_0.3_Acknowledgments.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_0.4_TOC.html">Table of Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_0.5_List-Tables-Figures.html">List of Tables &amp; List of Figures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_1.0_Purpose.html">1.0 Purpose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_2.0_Background.html">2.0 Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_3.0_Metadata-Standards.html">3.0 Metadata Standards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_4.0_Project.html">4.0 Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_5.0_Study-Area.html">5.0 Study Area</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_6.0_Survey.html">6.0 Surveys</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_7.0_Sample-Station_Camera-Location.html">7.0 Sample Station/Camera Location</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_8.0_Deployment.html">8.0 Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_9.0_Image_Sequence.html">9.0 Image/Sequence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_10.0_Data-Management.html">10.0 Data management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_11.0_Conclusion.html">11.0 Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_12.0_References.html">13.0 References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_metadata-standards/2_13.0_AppendixA.html">Appendix A</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Glossary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../3_glossary/3_Glossary.html">Glossary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/AB-RCSC/RCSC-WildCAM_Remote-Camera-Survey-Guidelines-and-Metadata-Standards" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/AB-RCSC/RCSC-WildCAM_Remote-Camera-Survey-Guidelines-and-Metadata-Standards/issues/new?title=Issue%20on%20page%20%2F1_survey-guidelines/1_7.0_Camera-deployment.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/1_survey-guidelines/1_7.0_Camera-deployment.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>7.0 Camera deployment</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-hardware-options">7.1 Camera hardware options</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#battery-type">7.1.1 Battery type</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sd-cards">7.1.2 SD cards</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-settings">7.2 Camera settings</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#photos-vs-video">7.2.1 Photos vs video</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trigger-mode-s-time-lapse-vs-motion-detector">7.2.2 Trigger Mode(s) - Time-lapse <em>vs.</em> motion detector</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trigger-sensitivity-photos-per-trigger-motion-image-interval-and-quiet-period">7.2.3 Trigger Sensitivity, Photos Per Trigger, Motion Image Interval and Quiet Period</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#attractants-vs-no-attractants">7.3 Attractants <em>vs.</em> no attractants</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-placement">7.4 Camera placement</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fov-target-feature">7.4.1 FOV Target Feature</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-height">7.4.2 Camera Height</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-angle">7.4.3 Camera angle</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-direction">7.4.4 Camera Direction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#field-of-view-fov-and-walktest">7.4.5 Field of View (FOV) and Walktest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-image">7.4.6 Test image</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deployment-area-photos-optional">7.4.7 Deployment Area Photos (optional)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-location-characteristics">7.4.8 Camera Location Characteristics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#field-equipment">7.4.9 Field equipment</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata">7.5 Metadata</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-deployment-service-and-retrieval">7.5.1 Metadata - Deployment, Service and Retrieval</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-information">7.5.2 Spatial information</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sd-card-retrieval">7.5.3 SD card retrieval</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="camera-deployment">
<span id="toc-surv-guidelines-camera-deployment"></span><h1>7.0 Camera deployment<a class="headerlink" href="#camera-deployment" title="Link to this heading">#</a></h1>
<p>Once the <a class="reference internal" href="../3_glossary/3_Glossary.html#project"><span class="std std-ref">project</span></a>-level aspects of a <a class="reference internal" href="../3_glossary/3_Glossary.html#survey"><span class="std std-ref">survey</span></a> have been decided, the next step is to consider the camera hardware options (e.g., <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-make"><span class="std std-ref">Camera Make</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Model</span></a>), camera settings, field equipment, whether to use attractants (<a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a>), camera placement considerations, and important metadata to collect.</p>
<section id="camera-hardware-options">
<span id="toc-surv-guidelines-camera-hardware-options"></span><h2>7.1 Camera hardware options<a class="headerlink" href="#camera-hardware-options" title="Link to this heading">#</a></h2>
<p>Remote cameras consist of a digital camera with a lens, external flash, and a passive infrared and/or motion detector (among other features; <a class="reference internal" href="#toc-surv-guidelines-fig-4"><span class="std std-ref">Figure 4</span></a>).</p>
<figure class="align-center" id="toc-surv-guidelines-fig-4">
<a class="reference internal image-reference" href="../_images/Survey-guidelines_CamFeatures.png"><img alt="../_images/Survey-guidelines_CamFeatures.png" src="../_images/Survey-guidelines_CamFeatures.png" style="width: 525.6px; height: 554.4px;" /></a>
</figure>
<p><strong>Figure 4.</strong> Examples of the a) external components and b) internal controls and components of a remote camera (Reconyx PC900; Reconyx Inc., 2017)</p>
<p>The camera “make” is the manufacturer of a particular camera (e.g., Reconyx), and the “model” is the model number of a particular camera (e.g., PC900). There are many different options and features to choose from when deciding upon the best <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-make"><span class="std std-ref">Camera Make</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Model</span></a> for a particular study, which differ in their impacts on <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a>. For this reason, deploying multiple <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Models</span></a> within a study is not advisable (Palencia et al., 2022; Wellington et al., 2014).</p>
<p>It is common for new camera users to confuse the specifications of a particular <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-make"><span class="std std-ref">Camera Make</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Model</span></a> with the camera’s settings. Specifications refer to the camera’s features (characteristics), while settings are options that the user can change. When choosing a <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-make"><span class="std std-ref">Camera Make</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Model</span></a>, important specifications include <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-speed"><span class="std std-ref">trigger speed</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#recovery-time"><span class="std std-ref">recovery time</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a> (i.e., the area [conical in shape] in which a remote camera can detect the heat signature and motion of an object Rovero &amp; Zimmermann, 2016; see <a class="reference internal" href="#toc-surv-guidelines-fig-5"><span class="std std-ref">Figure 5</span></a>), battery life and flash type. The best choice of <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Model</span></a> will depend on the <a class="reference internal" href="../3_glossary/3_Glossary.html#survey-objectives"><span class="std std-ref">Survey Objectives</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-approach"><span class="std std-ref">modelling approach</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#target-species"><span class="std std-ref">Target Species</span></a>, and physical environment.</p>
<p>Here are a few examples of specifications to achieve certain <a class="reference internal" href="../3_glossary/3_Glossary.html#survey-objectives"><span class="std std-ref">Survey Objectives</span></a>:</p>
<ul class="simple">
<li><p>To estimate <a class="reference internal" href="../3_glossary/3_Glossary.html#density"><span class="std std-ref">density</span></a> with the <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-rem"><span class="std std-ref">random encounter models (REM;</span></a> <a class="reference internal" href="../3_glossary/3_Glossary.html#density"><span class="std std-ref">density</span></a>) approach – use a camera with a fast <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-speed"><span class="std std-ref">trigger speed</span></a>, a wide <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a>, no-glow infrared (IR) flash, and the ability to take bursts of photos (Rovero et al., 2013).</p></li>
<li><p>To estimate <a class="reference internal" href="../3_glossary/3_Glossary.html#density"><span class="std std-ref">density</span></a> or abundance with mark-recapture methods – use a camera with a white flash, a short <a class="reference internal" href="../3_glossary/3_Glossary.html#recovery-time"><span class="std std-ref">recovery time</span></a>, and a fast <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-speed"><span class="std std-ref">trigger speed</span></a> (Rovero et al., 2013). Note that white flashes may scare some animals and potentially reduce the number of recaptures (Séquin et al., 2003; Wegge et al., 2004).</p></li>
<li><p><a class="reference internal" href="../3_glossary/3_Glossary.html#mods-occupancy"><span class="std std-ref">Occupancy studies</span></a> need a fast <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-speed"><span class="std std-ref">trigger speed</span></a> (<a class="reference internal" href="../3_glossary/3_Glossary.html#settings-trigger-sensitivity"><span class="std std-ref">Trigger Sensitivity</span></a> - high) (although the importance of which is species-dependent; Rovero et al., 2013).</p></li>
<li><p>Faunal detections generally require a fast <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-speed"><span class="std std-ref">trigger speed</span></a> (<a class="reference internal" href="../3_glossary/3_Glossary.html#settings-trigger-sensitivity"><span class="std std-ref">Trigger Sensitivity</span></a> - high) and a wide <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Most <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-approach"><span class="std std-ref">modelling approaches</span></a> require a fast <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-speed"><span class="std std-ref">trigger speed</span></a> (however, the use of <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> may compensate for slower <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-speed"><span class="std std-ref">trigger speeds</span></a> in some cases).</p>
</div>
<p>Given the numerous <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Models</span></a> available and the frequent release of new models, it would be difficult to recommend a make and model to fit all users’ needs. However, there are many studies and reviews that compare the specifications and the utility of different <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Models</span></a> (e.g., see <a class="reference external" href="https://www.trailcampro.com/collections/trail-camera-reviews">https://www.trailcampro.com/collections/trail-camera-reviews</a>; <a class="reference external" href="https://www.mammalweb.org/images/schools/Camera-trap-buying-guide.pdf">https://www.mammalweb.org/images/schools/Camera-trap-buying-guide.pdf</a>; Fisher &amp; Burton, 2012; Rovero et al., 2014; Rovero &amp; Zimmermann, 2016; Seccombe, 2017; Wearn &amp; Glover-Kapfer, 2017).</p>
<figure class="align-center" id="toc-surv-guidelines-fig-5">
<a class="reference internal image-reference" href="../_images/Survey-guidelines_FOV_DetZone.png"><img alt="../_images/Survey-guidelines_FOV_DetZone.png" src="../_images/Survey-guidelines_FOV_DetZone.png" style="width: 354.0px; height: 379.8px;" /></a>
</figure>
<p><strong>Figure 5.</strong> The ability to detect an animal will vary according to the camera specifications (and settings). Important specifications include the camera’s detection zone (here termed “trigger area”), Field of View (FOV; “viewable area’), and”registration area” (the area in which an animal entering has at least some probability of being captured on the image) (Moeller et al., 2023).</p>
<section id="battery-type">
<span id="toc-surv-guidelines-battery-type"></span><h3>7.1.1 Battery type<a class="headerlink" href="#battery-type" title="Link to this heading">#</a></h3>
<p>Most remote cameras require AA batteries. It is recommended to use <strong>lithium batteries,</strong> as opposed to alkaline or nickel metal hydride, because they are less affected by cold temperatures. Battery life will be affected not only by the type of batteries but also by the camera settings, temperature, and number of images or videos taken (which are dependent on the camera settings, placement, and level of activity in front of the camera) (Wearn &amp; Glover-Kapfer, 2017). However, some camera user manuals contain information on battery performance and the total number of images a camera can be expected to collect before the batteries die (based on the operating temperature and battery type, e.g., <a class="reference external" href="https://images.reconyx.com/file/HyperFireManual.pdf">Reconyx HyperFire Instruction Manual</a> [Reconyx Inc., 2017]).</p>
</section>
<section id="sd-cards">
<span id="toc-surv-guidelines-sd-cards"></span><h3>7.1.2 SD cards<a class="headerlink" href="#sd-cards" title="Link to this heading">#</a></h3>
<p>It is important to consider the <strong>size</strong>, <strong>type</strong>, and <strong>class</strong> of <strong>SD (Secure Digital) card</strong> since the available options vary in storage capacity, compatibility, and write-speed (Wearn &amp; Glover-Kapfer, 2017).</p>
<p>The <strong>size of the SD card</strong> (i.e., storage capacity) should be considered in relation to the expected duration of <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment"><span class="std std-ref">deployment</span></a>, the deployment area, and the level of activity expected to occur in front of the camera. For example, a camera placed in a grassy area might be expected to produce more <a class="reference internal" href="../3_glossary/3_Glossary.html#false-trigger"><span class="std std-ref">false triggers</span></a> due to grass waving in front of the camera. Or perhaps a camera placed near a den might be expected to have higher animal activity. Both situations might warrant using a larger SD card. A 4 GB SD card is capable of storing ~8,000-20,000 images (400-900 KB in size), which might be sufficient if you plan to revisit the camera frequently (~every four weeks) (Wearn &amp; Glover-Kapfer, 2017). We suggest using a card with at least 16 GB, and Wearn &amp; Glover-Kapfer (2017) suggest larger (32 GB) if the video is enabled or if the camera will be active for long periods.</p>
<p>There are three <strong>types of SD card:</strong> standard (SD; maximum memory of 2 GB), high-capacity (SDHC; maximum memory of 32 GB) and extended-capacity (SDXC; maximum memory of &gt; 32 GB) (Wearn &amp; Glover-Kapfer, 2017). Note that SDHC cards are not compatible with most <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Models</span></a>. Be sure to check the camera user manual to confirm the compatible SD card type(s) (Wearn &amp; Glover-Kapfer, 2017).</p>
<p>The <strong>“class” of an SD card</strong> (e.g., class 2, 4, 6, or 10) indicates the “write-speed” (i.e., the speed at which the SD card can read and write data; Wearn &amp; Glover-Kapfer, 2017). Slower write speeds may perform poorly if the camera is set to collect images continuously, as fast as possible (i.e., rapid-fire or “near-video”) or if the video setting is activated. It is recommended to use an SD card of class 4 or higher, ideally class 10 (Wearn &amp; Glover-Kapfer, 2017).</p>
<p>Caution should be used when deploying older SD cards (Wearn &amp; Glover-Kapfer, 2017) and, perhaps, microSD card types; a few remote camera users in Alberta have described a 50% SD card failure rate with microSD cards (St. Clair, personal communications). See Wearn &amp; Glover-Kapfer (2017) for additional information on choosing and maintaining (i.e., regularly formatting) SD cards.</p>
</section>
</section>
<section id="camera-settings">
<span id="toc-surv-guidelines-camera-settings"></span><h2>7.2 Camera settings<a class="headerlink" href="#camera-settings" title="Link to this heading">#</a></h2>
<p>As mentioned above, in <a class="reference internal" href="#TOC_surv_guidelines_camera_hardware_options"><span class="std std-ref">camera hardware options</span></a>, it is important to distinguish between camera specifications (features) versus settings (user-defined options). Important settings often include <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-trigger-sensitivity"><span class="std std-ref">Trigger Sensitivity</span></a> (which may affect <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a>), <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-motion-image-interval"><span class="std std-ref">Motion Image Interval</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-quiet-period"><span class="std std-ref">Quiet Period</span></a>. The setting option selected may vary according to the <a class="reference internal" href="../3_glossary/3_Glossary.html#survey-objectives"><span class="std std-ref">Survey Objectives</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-approach"><span class="std std-ref">modelling approach</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#target-species"><span class="std std-ref">Target Species</span></a>, and use (or not) of attractants. Consideration of the camera settings is an important step when designing a <a class="reference internal" href="../3_glossary/3_Glossary.html#survey"><span class="std std-ref">survey</span></a> and in the interpretation of the resulting images.</p>
<p>An example of the settings available in a Reconyx camera is included in <a class="reference internal" href="1_10.1_AppendixA-Tables.html#TOC_surv_guidelines_table_aurv_guidelines_photos-vs-video"><span class="std std-ref">Appendix A - Table A3</span></a>.</p>
<section id="photos-vs-video">
<span id="toc-surv-guidelines-photos-vs-video"></span><h3>7.2.1 Photos vs video<a class="headerlink" href="#photos-vs-video" title="Link to this heading">#</a></h3>
<p>Some <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Models</span></a> allow the user to record video as well as photos. Videos typically use more memory on SD cards, drain camera batteries sooner and are more difficult to process (i.e., extract data) than images. Limiting the length of video taken when the camera is <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-event"><span class="std std-ref">triggered</span></a> (possible for most <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Models</span></a>) could help slow how quickly an SD card becomes full. Some <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Models</span></a> have hybrid settings, which lets you capture photos and videos for each animal detection.</p>
<p>It is generally recommended that cameras are set to capture images rather than videos unless the <a class="reference internal" href="../3_glossary/3_Glossary.html#survey-objectives"><span class="std std-ref">objective</span></a> is related to monitoring animal behaviours, understanding group size and/or determining recruitment (e.g. calves per female), in which case continuous observation may be important. Video is also useful when individual identification is needed, such as for creating “marked” individuals for use in machine learning or computer vision (e.g., Schneider et al., 2019; Vidal et al., 2021).</p>
<p>By default, cameras are set to record images when an animal is detected by the motion and/or infrared detector(s).</p>
</section>
<section id="trigger-mode-s-time-lapse-vs-motion-detector">
<span id="toc-surv-guidelines-trigger-modes-timelapse-vs-motion-detector"></span><h3>7.2.2 Trigger Mode(s) - Time-lapse <em>vs.</em> motion detector<a class="headerlink" href="#trigger-mode-s-time-lapse-vs-motion-detector" title="Link to this heading">#</a></h3>
<p>By default, remote cameras are <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-event"><span class="std std-ref">triggered</span></a> to take photos when the motion detector detects an animal. Many <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Models</span></a> allow you to set your camera in both <a class="reference internal" href="../3_glossary/3_Glossary.html#timelapse-image"><span class="std std-ref">time-lapse</span></a> and default motion detector settings.</p>
<p><a class="reference internal" href="../3_glossary/3_Glossary.html#timelapse-image"><span class="std std-ref">Time-lapse images</span></a> are images taken at regular intervals (e.g., hourly or daily, on the hour), regardless of whether an animal is present or not. It is critical to take a minimum of one <a class="reference internal" href="../3_glossary/3_Glossary.html#timelapse-image"><span class="std std-ref">time-lapse image</span></a> per day at a consistent time (e.g., 12:00 p.m. [noon]) to create a record of camera functionality or local environmental conditions (e.g., snow cover, plant growth, wildfire; Sun et al., 2021)</p>
<p><a class="reference internal" href="../3_glossary/3_Glossary.html#timelapse-image"><span class="std std-ref">Time-lapse images</span></a> may always be useful for <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-approach"><span class="std std-ref">modelling approaches</span></a> that require estimation of the “<a class="reference internal" href="../3_glossary/3_Glossary.html#fov-viewshed"><span class="std std-ref">viewshed</span></a>“ (i.e., “<a class="reference internal" href="../3_glossary/3_Glossary.html#fov-viewshed-density-estimators"><span class="std std-ref">viewshed density estimators</span></a>,” such as <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-rem"><span class="std std-ref">REM</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-tte"><span class="std std-ref">time-to-event (TTE)</span></a> models; see Moeller et al., [2018] for advantages and disadvantages).</p>
</section>
<section id="trigger-sensitivity-photos-per-trigger-motion-image-interval-and-quiet-period">
<span id="toc-surv-guidelines-trigger-sensitivity-photos-per-trigger-motion-image-interval-and-quiet-period"></span><h3>7.2.3 Trigger Sensitivity, Photos Per Trigger, Motion Image Interval and Quiet Period<a class="headerlink" href="#trigger-sensitivity-photos-per-trigger-motion-image-interval-and-quiet-period" title="Link to this heading">#</a></h3>
<p>The <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-trigger-sensitivity"><span class="std std-ref"><strong>Trigger Sensitivity</strong></span></a> is camera setting responsible for how sensitive a camera is to activation (to “<a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-event"><span class="std std-ref">triggering</span></a>”) via the infrared and/or heat detectors (if applicable, e.g., Reconyx HyperFire cameras have a choice between “Low,” “Low/Med,” “Med,” “Med/High,” “High,” “Very high” and “Unknown”). That is, how the camera is activated once the animal enters the <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a>. A high <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-trigger-sensitivity"><span class="std std-ref">Trigger Sensitivity</span></a> is ideal when estimating <a class="reference internal" href="../3_glossary/3_Glossary.html#density"><span class="std std-ref">density</span></a> or abundance using mark-recapture or <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-occupancy"><span class="std std-ref">occupancy modelling</span></a> (Rovero et al., 2013). The more easily (and faster) the camera is <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-event"><span class="std std-ref">triggered</span></a>, the more likely it is to photograph approaching animals as they enter the area (Apps &amp; McNutt, 2018). High <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-trigger-sensitivity"><span class="std std-ref">Trigger Sensitivity</span></a> (and fast <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-motion-image-interval"><span class="std std-ref">Motion Image Intervals</span></a>) are less necessary if attractants are present (Rovero et al., 2013). Refer to <a class="reference internal" href="1_6.0_Study-design.html#TOC_surv_guidelines_site_selection_and_camera_arrangement"><span class="std std-ref">section 6.2</span></a> for examples of ideal <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-trigger-sensitivity"><span class="std std-ref">Trigger Sensitivity</span></a> settings to achieve certain <a class="reference internal" href="../3_glossary/3_Glossary.html#survey-objectives"><span class="std std-ref">Survey Objectives</span></a>.</p>
<p>The camera user can also predefine the number of photos taken each time the camera is <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-event"><span class="std std-ref">triggered</span></a> (i.e., “<a class="reference internal" href="../3_glossary/3_Glossary.html#settings-photos-per-trigger"><span class="std std-ref">Photos Per Trigger</span></a>, e.g., 1, 2, 3, 5 or 10 photos). The user can specify the time interval between images (i.e., the “<a class="reference internal" href="../3_glossary/3_Glossary.html#settings-motion-image-interval"><span class="std std-ref">Motion Image Interval</span></a>“) or the time interval between image <a class="reference internal" href="../3_glossary/3_Glossary.html#sequence"><span class="std std-ref">sequences</span></a> (i.e., the “<a class="reference internal" href="../3_glossary/3_Glossary.html#settings-quiet-period"><span class="std std-ref"><strong>Quiet Period</strong></span></a>“ or “time lag,” depending on the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-make"><span class="std std-ref">Camera Make</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Model</span></a>). The <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-quiet-period"><span class="std std-ref">Quiet Period</span></a> differs from the <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-motion-image-interval"><span class="std std-ref">Motion Image Interval</span></a> in that the delay occurs between multi-image <a class="reference internal" href="../3_glossary/3_Glossary.html#sequence"><span class="std std-ref">sequences</span></a> rather than between the images contained within multi-image <a class="reference internal" href="../3_glossary/3_Glossary.html#sequence"><span class="std std-ref">sequences</span></a> (as in <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-motion-image-interval"><span class="std std-ref">Motion Image Interval</span></a>). Setting the camera to take continuous photos (i.e., the <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-quiet-period"><span class="std std-ref">Quiet Period</span></a> set to “no delay”) will fill the SD card with more photos per detection; however, it may provide important information for identifying individual animals, determining enter-leave times and regarding animal behaviours / interactions.</p>
<p>Generally, it is recommended to set the <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-trigger-sensitivity"><span class="std std-ref">Trigger Sensitivity</span></a> to “high,” <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-photos-per-trigger"><span class="std std-ref">Photos Per Trigger</span></a> to “1” and the <a class="reference internal" href="../3_glossary/3_Glossary.html#settings-quiet-period"><span class="std std-ref">Quiet Period</span></a> to “no delay” between consecutive <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-event"><span class="std std-ref">triggers</span></a> (<a class="reference internal" href="1_10.1_AppendixA-Tables.html#TOC_surv_guidelines_table_a3"><span class="std std-ref">Appendix A - Table A3</span></a>).</p>
</section>
</section>
<section id="attractants-vs-no-attractants">
<span id="toc-surv-guidelines-attractants-vs-no-attractants"></span><h2>7.3 Attractants <em>vs.</em> no attractants<a class="headerlink" href="#attractants-vs-no-attractants" title="Link to this heading">#</a></h2>
<p>Attractants (i.e., <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a>) can increase the <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a> by drawing animals into the camera’s <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a>, thereby effectively increasing the sampled area.</p>
<p><a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">Bait</span></a> is a food item (or other substance) that is placed to attract animals via the sense of taste and olfactory cues (Schlexer, 2008). <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">Lure</span></a> is any substance that draws animals closer; <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lures</span></a> include <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-scent-lure"><span class="std std-ref">scent (olfactory) lure</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-visual-lure"><span class="std std-ref">visual lure</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-audible-lure"><span class="std std-ref">audible lure</span></a> (Schlexer, 2008).</p>
<p>There are many options of <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> available, and those used in camera studies have included commercial <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-scent-lure"><span class="std std-ref">scent lures</span></a>, food <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a>s, carcasses and compact disks (see Wearn &amp; Glover-Kapfer, 2017 for details and examples). <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-scent-lure"><span class="std std-ref">Scent lure</span></a> is typically applied to objects in the <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a> (e.g., trees or rocks), whereas a food <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> is generally hung up or placed behind wire mesh to limit tampering by animals. Food rewards (<a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">baits</span></a> or carcasses) are also used but are more likely to influence behaviour and inter- and intra-specific interactions (e.g., avoidance of an area or conflict between individuals or species) and may result in food conditioning, which in turn may lead to human-wildlife conflict.</p>
<p>Some options are costly and require frequent reapplication during the <a class="reference internal" href="../3_glossary/3_Glossary.html#survey"><span class="std std-ref">survey</span></a> <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment"><span class="std std-ref">deployment</span></a>. Users should consider the additional cost of supplies and labour required to revisit the field to reapply at the frequency necessary to maintain effectiveness. <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-scent-lure"><span class="std std-ref">Scent lure</span></a> dispensers, such as those developed by the Woodland Park Zoo, may help reduce the number of visits needed for reapplication and associated costs.</p>
<p>Few studies have compared the efficacy of different types of attractants, but both Espartosa et al. (2011) and Thorn et al. (2009) suggested that food <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">baits</span></a> are more effective than <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-scent-lure"><span class="std std-ref">scent lures</span></a> for many species (although these evaluations did not include wildlife species from Canada).</p>
<p>Since species may respond to <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> types and scents differently, the type of <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> chosen (if any) should be based on the biology of the <a class="reference internal" href="../3_glossary/3_Glossary.html#target-species"><span class="std std-ref">Target Species</span></a> but also on the <a class="reference internal" href="../3_glossary/3_Glossary.html#survey-objectives"><span class="std std-ref">Survey Objectives</span></a> and the <a class="reference internal" href="../3_glossary/3_Glossary.html#survey"><span class="std std-ref">survey</span></a> environment. For example, liquid products may be less suitable in areas where precipitation is high. Some <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> types smell like the urine of a particular species, which could result in higher detections of certain species by activating an investigative response while resulting in avoidance by other species. Interestingly, a <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2020.01.30.926618v1.abstract">study</a> (Holinda et al., 2020) by members of WildCAM found no evidence that <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-scent-lure"><span class="std std-ref">scent lure</span></a> placed at camera stations repelled non-target (i.e., prey) animals (see also Mills et al., 2019); rather, both predators and prey showed varied responses to the <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-scent-lure"><span class="std std-ref">scent lure</span></a>.</p>
<p>For many <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-approach"><span class="std std-ref">modelling approaches</span></a>, placing <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> may violate <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-assumption"><span class="std std-ref">model assumptions</span></a> and increase the likelihood of biased results (e.g., <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> might amplify measures of occurrence, biasing estimates of space use [Stewart et al., 2019]). Attractants may also introduce variation in the response by species, individuals or <a class="reference internal" href="../3_glossary/3_Glossary.html#sex-class"><span class="std std-ref">Sex Class</span></a>es (or over space or time) that would not naturally occur. It may be possible to address biased samples in the analysis stage, but this can require substantial amounts of data.</p>
<p>In contrast, placing <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> can also help to better satisfy the <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-assumption"><span class="std std-ref">assumptions</span></a> of some <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-approach"><span class="std std-ref">modelling approaches</span></a>. For example, attractants might be deployed to help satisfy the <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-assumption"><span class="std std-ref">assumption</span></a> of constant <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a> of <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-occupancy"><span class="std std-ref">occupancy</span></a> (when using a <a class="reference internal" href="../3_glossary/3_Glossary.html#sampledesign-systematic-random"><span class="std std-ref">systematic random design</span></a>), <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-relative-abundance"><span class="std std-ref">relative abundance</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-cr-cmr"><span class="std std-ref">capture-recapture (CR</span></a>; Karanth, 1995; Karanth &amp; Nichols, 1998) models by increasing individuals’ <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a> (Wearn &amp; Glover-Kapfer, 2017).</p>
<p><a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">Bait</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> may be a “necessity” for species (or areas) where detection is unlikely without a large number of remote cameras or lengthy <a class="reference internal" href="../3_glossary/3_Glossary.html#survey"><span class="std std-ref">surveys</span></a>. Most studies that use attractants target carnivore species, which are often elusive, difficult to monitor and occur at low densities.</p>
<p>In general, we recommend against the use of <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> for <a class="reference internal" href="../3_glossary/3_Glossary.html#project"><span class="std std-ref">projects</span></a> focused on unbiased detection of as many species as possible. Overall, the use of attractants is not recommended unless the study is an <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-occupancy"><span class="std std-ref">occupancy</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-cr-cmr"><span class="std std-ref">capture-recapture</span></a> study of a <a class="reference internal" href="../3_glossary/3_Glossary.html#target-species"><span class="std std-ref">Target Species</span></a>with low <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a> (Wearn &amp; Glover-Kapfer, 2017).</p>
<p>We advise against the use of <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> in or near urban areas due to the possible increase in human-wildlife conflict. To minimize this potential, <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a> should not be placed within 200 m of residences, industrial or recreational facilities, campgrounds, 100 m of active human-use trails (e.g., hiking trails), or 50 m of roads.</p>
<p>Where attractants are used, users must follow provincial policy and legislation (e.g., <a class="reference external" href="https://www.bclaws.gov.bc.ca/civix/document/id/complete/statreg/00_96488_01#section33">BC Wildlife Act – Section 33.1</a>, <a class="reference external" href="https://open.alberta.ca/publications/w10#:~:text=The%20Act%20provides%20for%20the,controlled%20animals%20and%20endangered%20species.">Alberta Wildlife Act</a> and <a class="reference external" href="https://open.alberta.ca/publications/1997_143">Wildlife Regulation</a>), as well as local bylaws. Before deploying any remote cameras in the field, users must also obtain the necessary permits from provincial and/or research institutions (e.g., animal care permits). In Alberta, a wildlife research and collection permit is required when using <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a> or <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-lure"><span class="std std-ref">lure</span></a>. Special conditions or restrictions may also apply. Refer to <a class="reference external" href="https://www.alberta.ca/wildlife-research-and-collection.aspx">https://www.alberta.ca/wildlife-research-and-collection.aspx</a> for further details. In British Columbia, a research permit is required when using <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">bait</span></a>, but not <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-scent-lure"><span class="std std-ref">scent lure</span></a>. Special conditions or restrictions may also apply in each province.</p>
<p>Consideration of placement locations should include proximity and potential impacts to First Nations Reserves and Metis Settlements. You can find information on First Nations Reserves and Metis Settlements using the <a class="reference external" href="https://www.alberta.ca/proponent-led-indigenous-consultations.aspx">Landscape Analysis Indigenous Relations Tool (LAIRT)</a> (Government of Alberta, 2023a) located within the <a class="reference external" href="https://www.alberta.ca/lat-overview.aspx">Landscape Analysis Tool (LAT)</a> (Government of Alberta, 2023b) (see “Non-Administered Areas”). The results produced by LAIRT do not provide an official list of First Nations and Metis settlements to consult if consultation is required since “LAIRT will report on where government ordinarily considers requiring consultation with a particular First Nation or Metis Settlement, which is subject to be revised at any time” (Government of Alberta, 2023a).</p>
</section>
<section id="camera-placement">
<span id="toc-surv-guidelines-camera-placement"></span><h2>7.4 Camera placement<a class="headerlink" href="#camera-placement" title="Link to this heading">#</a></h2>
<p>When deploying a remote camera, important considerations include whether to place cameras on or aim cameras toward specific features, as well as the attachment point, <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-height"><span class="std std-ref">height</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-angle"><span class="std std-ref">angle</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-direction"><span class="std std-ref">direction</span></a>.</p>
<p>The information in this section is also included in a step-by-step description of the <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment"><span class="std std-ref">deployment</span></a> process (<a class="reference internal" href="1_10.1_AppendixA-Tables.html#TOC_surv_guidelines_table_a5"><span class="std std-ref">Appendix A - Table A5</span></a>).</p>
<section id="fov-target-feature">
<span id="toc-surv-guidelines-fov-target-feature"></span><h3>7.4.1 FOV Target Feature<a class="headerlink" href="#fov-target-feature" title="Link to this heading">#</a></h3>
<p>Remote cameras may be deployed to capture detections on specific man-made or natural features (i.e., “<a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Feature</span></a>“) to maximize the detection of wildlife species or to measure the use of that feature. “<a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Features</span></a> may include, for example, game trails, human trails, watering holes, mineral licks, rub trees, nest sites, etc.</p>
<p><a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Features</span></a> differ from <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location-characteristics"><span class="std std-ref">Camera Location Characteristics</span></a> (see below) in that <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Features</span></a> are features the camera is aimed towards (e.g., a seismic line). In contrast, a <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location-characteristics"><span class="std std-ref">Camera Location Characteristics</span></a> may include features outside of the camera’s <a class="reference internal" href="../3_glossary/3_Glossary.html#field-of-view"><span class="std std-ref">FOV</span></a> (e.g., meadow habitat).</p>
<p>The decision of where exactly to place the camera will be influenced by the feature to target, the <a class="reference internal" href="../3_glossary/3_Glossary.html#survey-objectives"><span class="std std-ref">Survey Objectives</span></a> and the number of <a class="reference internal" href="../3_glossary/3_Glossary.html#target-species"><span class="std std-ref">Target Species</span></a>, and, importantly, the sampling design, intended analysis and associated statistical <a class="reference internal" href="../3_glossary/3_Glossary.html#mods-modelling-assumption"><span class="std std-ref">assumption</span></a>s.</p>
<p>Deploying cameras on or near <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Features</span></a> can provide meaningful information for some <a class="reference internal" href="../3_glossary/3_Glossary.html#survey-objectives"><span class="std std-ref">objectives</span></a>, but often introduces detection biases (Wearn &amp; Glover-Kapfer, 2017). These biases make it difficult to extrapolate findings to areas without these features or to collect data on multiple <a class="reference internal" href="../3_glossary/3_Glossary.html#target-species"><span class="std std-ref">Target Species</span></a>that vary in their use of these features (Wearn &amp; Glover-Kapfer, 2017). To reduce potential biases, cameras should ideally be deployed using a <a class="reference internal" href="../3_glossary/3_Glossary.html#sampledesign-paired"><span class="std std-ref">paired design</span></a>, with cameras on- and off-<a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Features</span></a> (e.g., on- and off-trails).</p>
<p>In general, cameras should be placed approximately <strong>3–5 m from the</strong> <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Feature</span></a> (<a class="reference internal" href="#toc-surv-guidelines-fig-6"><span class="std std-ref">Figure 6</span></a>; the “<a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target-distance"><span class="std std-ref">FOV Target Feature Distance (m)</span></a>“ <a class="reference internal" href="#toc-surv-guidelines-fig-7"><span class="std std-ref">Figure 7</span></a>). If cameras are placed too close to the <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Feature</span></a>, some species may not be detected since the camera may be too high to capture smaller species or the movement speed of certain species. In contrast, if cameras are placed too far from the <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Feature</span></a> (e.g., &gt; 5 m), animals detected at night may not be visible in the images because they are less likely to be illuminated by the infrared flash.</p>
<p>This recommendation can be relaxed if users plan to estimate the <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-distance"><span class="std std-ref">detection distance</span></a> (i.e., “the maximum distance that a sensor can detect a target” [Wearn and Glover-Kapfer, 2017]) and account for variability in <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a>.</p>
<figure class="align-center" id="toc-surv-guidelines-fig-6">
<a class="reference internal image-reference" href="../_images/Survey-guidelines_WildCAM-FOV.png"><img alt="../_images/Survey-guidelines_WildCAM-FOV.png" src="../_images/Survey-guidelines_WildCAM-FOV.png" style="width: 377.29999999999995px; height: 347.2px;" /></a>
</figure>
<p><strong>Figure 6.</strong> Illustration of a remote camera showing (A) the <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Feature</span></a> (a trail), (B) the camera’s <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a> (everything inside the red outline), and (C) the distance of the camera to the <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Feature</span></a>. Note that the <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a> will vary according to <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-make"><span class="std std-ref">Camera Make</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Model</span></a>. Camera users will need to identify a suitable attachment point (e.g., tree, fence post/ stake) near the target area. The most suitable attachment point will depend on the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-height"><span class="std std-ref">Camera Height</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-angle"><span class="std std-ref">angle</span></a>, and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-direction"><span class="std std-ref">direction</span></a> since these choices will impact the <a class="reference internal" href="../3_glossary/3_Glossary.html#field-of-view"><span class="std std-ref">FOV</span></a> (see <a class="reference internal" href="#toc-surv-guidelines-camera-placement"><span class="std std-ref">section 7.4</span></a>). Figure from WildCAM Network (2019).</p>
</section>
<section id="camera-height">
<span id="toc-surv-guidelines-camera-height"></span><h3>7.4.2 Camera Height<a class="headerlink" href="#camera-height" title="Link to this heading">#</a></h3>
<p>The <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-height"><span class="std std-ref"><strong>Camera Height</strong></span></a> is the height from the ground (below snow) to the bottom of the lens (metres; to the nearest 0.05 m). Cameras should be positioned and secured to an attachment point at <strong>~0.5–1 m height</strong> (from the ground to the bottom of the lens; Meek et al., 2014). The most appropriate <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-height"><span class="std std-ref">Camera Height</span></a> will be influenced by the terrain (e.g., slope), the angle of the tree, as well as the <a class="reference internal" href="../3_glossary/3_Glossary.html#target-species"><span class="std std-ref">Target Species</span></a>. Cameras placed closer to the ground reduce the probability that large animals (e.g., moose) will be fully in the frame in the photos. Similarly, if the camera is placed too high, only larger animals will activate the motion detector, and smaller species may be missed (e.g., hares, squirrels, marten) (Meek et al., 2016). The user should ensure that the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-height"><span class="std std-ref">Camera Height</span></a> adequately detects motion at a specified <a class="reference internal" href="../3_glossary/3_Glossary.html#walktest-distance"><span class="std std-ref">Walktest Distance (m)</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#walktest-height"><span class="std std-ref">Walktest Height (m)</span></a>. If snow is a consideration, users may need to place cameras higher or plan to revisit seasonally to adjust as needed, being sure to record adjustments that could affect <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a>.</p>
</section>
<section id="camera-angle">
<span id="toc-surv-guidelines-camera-angle"></span><h3>7.4.3 Camera angle<a class="headerlink" href="#camera-angle" title="Link to this heading">#</a></h3>
<p>The <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-angle"><span class="std std-ref"><strong>camera angle</strong></span></a> is the degree to which the camera is pointed towards the <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Feature</span></a> relative to the horizontal ground surface (with respect to slope, if applicable). The <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-angle"><span class="std std-ref">camera angle</span></a> differs from the camera <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-viewshed"><span class="std std-ref">viewshed</span></a> angle, which is the area visible to the camera as determined by its camera lens angle and trigger distance (Moeller et al., 2023).</p>
<p>Cameras should be <strong>angled slightly downward</strong>, such that they should be able to detect both small and large species at a target distance of approximately <strong>3–5 m</strong> from the camera and/or the user ensures that the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-angle"><span class="std std-ref">angle</span></a> adequately detects motion at a specified <a class="reference internal" href="../3_glossary/3_Glossary.html#walktest-distance"><span class="std std-ref">Walktest Distance (m)</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#walktest-height"><span class="std std-ref">Walktest Height (m)</span></a>. Cameras should not be angled upwards, as upward facing angles will result in fewer detections, especially of smaller species (Glen et al., 2013). If snow is a consideration, users may need to angle cameras higher or plan to revisit seasonally to adjust as needed, being sure to record adjustments that could affect <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a>.</p>
</section>
<section id="camera-direction">
<span id="toc-surv-guidelines-camera-direction"></span><h3>7.4.4 Camera Direction<a class="headerlink" href="#camera-direction" title="Link to this heading">#</a></h3>
<p>The <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-direction"><span class="std std-ref"><strong>Camera Direction</strong></span></a> is the cardinal direction that a camera faces. Cameras are usually positioned to maximize detections of the <a class="reference internal" href="../3_glossary/3_Glossary.html#target-species"><span class="std std-ref">Target Species</span></a> (except when <a class="reference internal" href="../3_glossary/3_Glossary.html#sampledesign-random"><span class="std std-ref">random</span></a> placement is required).</p>
<p>The direction a camera faces is an important consideration because it affects the amount of light that reaches the area, which has implications for both <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-probability"><span class="std std-ref">detection probability</span></a> and image quality (reduced quality via sun glare). Ideally, cameras should face north (N, i.e. “0” degrees), or south (S; i.e. “180” degrees) if north is not possible. Sun glare is the most problematic for cameras that face east or west by causing <a class="reference internal" href="../3_glossary/3_Glossary.html#false-trigger"><span class="std std-ref">false triggers</span></a> unless there is thick tree cover blocking the sun (standing water may also produce similar problems with sun glare).</p>
<p>The camera direction should be chosen to ensure the field of view (FOV) is of the original FOV target feature. Generally, cameras should be placed <strong>perpendicular to the expected direction of animal travel</strong> (e.g., along a game or human trail). Since there is a delay between when an animal enters the camera’s <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a> and when it captures an image, placing the camera perpendicular to the trail increases the likelihood that an animal will be in the frame when the camera <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-event"><span class="std std-ref">triggers</span></a> (Apps &amp; McNutt, 2018). The delay is typically &lt; 1 s, depending on the <a class="reference internal" href="../3_glossary/3_Glossary.html#trigger-speed"><span class="std std-ref">trigger speed</span></a> for a particular camera and the settings applied. The size of the <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-zone"><span class="std std-ref">detection zone</span></a> will depend on the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-make"><span class="std std-ref">Camera Make</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Model</span></a>.</p>
</section>
<section id="field-of-view-fov-and-walktest">
<span id="toc-surv-guidelines-fov-and-walktest"></span><h3>7.4.5 Field of View (FOV) and Walktest<a class="headerlink" href="#field-of-view-fov-and-walktest" title="Link to this heading">#</a></h3>
<p>It is important to try to ensure an unobstructed <a class="reference internal" href="../3_glossary/3_Glossary.html#field-of-view"><span class="std std-ref">Field of View (FOV)</span></a> from the camera to avoid impairing the <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-rate"><span class="std std-ref">detection rates</span></a> of wildlife (or humans). Moll et al. (2019) reported decreased <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-rate"><span class="std std-ref">detection rates</span></a> with increasing obstruction for most mammals in their study and two- to three-fold decreases in detections per week per camera. They concluded that it was critical to account for <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-viewshed"><span class="std std-ref">viewshed</span></a> obstruction when interpreting <a class="reference internal" href="../3_glossary/3_Glossary.html#detection-rate"><span class="std std-ref">detection rates</span></a> as indices of abundance and habitat use.</p>
<p>To determine a camera’s <a class="reference internal" href="../3_glossary/3_Glossary.html#field-of-view"><span class="std std-ref">FOV</span></a>, a <a class="reference internal" href="../3_glossary/3_Glossary.html#walktest"><span class="std std-ref">walktest</span></a> should be performed every time a camera is deployed or re-positioned. See the camera’s user manual for instructions on how to perform the <a class="reference internal" href="../3_glossary/3_Glossary.html#walktest"><span class="std std-ref">walktest</span></a> for your particular <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-make"><span class="std std-ref">Camera Make</span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-model"><span class="std std-ref">Camera Model</span></a> (see also <a class="reference internal" href="1_10.1_AppendixA-Tables.html#TOC_surv_guidelines_table_a5"><span class="std std-ref">Appendix A - Table A5</span></a>).</p>
<p>An <strong>unobstructed</strong> <a class="reference internal" href="../3_glossary/3_Glossary.html#field-of-view"><span class="std std-ref"><strong>FOV</strong></span></a> <strong>of at least 5 m wide and 10 m long</strong> is ideal for capturing wildlife images in most cases. To achieve this desired <a class="reference internal" href="../3_glossary/3_Glossary.html#field-of-view"><span class="std std-ref">FOV</span></a>, ensure that the camera is detecting motion 5 m in front of the camera, at both 0 m and 0.5–1 m heights (<a class="reference internal" href="#toc-surv-guidelines-fig-7"><span class="std std-ref">Figure 7</span></a>).</p>
<p>This may require repositioning the camera to avoid large objects (e.g., rocks, logs) and/or trimming or removing vegetation that interferes with the visibility of the target area (or is likely to in the future). These objects may block areas within the camera’s <a class="reference internal" href="../3_glossary/3_Glossary.html#field-of-view"><span class="std std-ref">FOV</span></a> and reflect the flash, making it more difficult to detect animals at night. Trimming or removing vegetation will also minimize the likelihood of <a class="reference internal" href="../3_glossary/3_Glossary.html#false-trigger"><span class="std std-ref">false triggers</span></a> (i.e., blank images (no wildlife or human present) that can occur because of blowing vegetation). <a class="reference internal" href="../3_glossary/3_Glossary.html#false-trigger"><span class="std std-ref">False triggers</span></a> will drain batteries and fill SD cards and increase the time to process images.</p>
<p>Important considerations with respect to <a class="reference internal" href="../3_glossary/3_Glossary.html#field-of-view"><span class="std std-ref">FOV</span></a> include:</p>
<ul class="simple">
<li><p>Situations (e.g., open habitats) where animals in background my be viewable but would not trigger the detector (sensor),</p></li>
<li><p>how animals in the distance should be treated (i.e., at what distance is an animal captured in an image no longer considered a detection)</p></li>
</ul>
<p>Placing a stake in front of the camera at a specified distance (i.e., the “stake distance”) is one method used to standardize the <a class="reference internal" href="../3_glossary/3_Glossary.html#field-of-view"><span class="std std-ref">FOV</span></a>. Applying a standardized reference distance can help with interpretation and analysis (ABMI, 2021).</p>
<figure class="align-center" id="toc-surv-guidelines-fig-7">
<a class="reference internal image-reference" href="../_images/Survey-guidelines_walktest-height.png"><img alt="../_images/Survey-guidelines_walktest-height.png" src="../_images/Survey-guidelines_walktest-height.png" style="width: 625.0999999999999px; height: 387.09999999999997px;" /></a>
</figure>
<p><strong>Figure 7.</strong> The <a class="reference internal" href="../3_glossary/3_Glossary.html#walktest-distance"><span class="std std-ref"><strong>Walktest Distance</strong></span></a> and <a class="reference internal" href="../3_glossary/3_Glossary.html#walktest-height"><span class="std std-ref"><strong>Walktest Height</strong></span></a> are the horizontal and vertical distances from the camera, respectively, at which the user performs the walk test. A <a class="reference internal" href="../3_glossary/3_Glossary.html#walktest"><span class="std std-ref">walktest</span></a> should be performed 5 m away from the camera, at both 0 m (ground) and 0.5–1 m height.</p>
</section>
<section id="test-image">
<span id="toc-surv-guidelines-test-image"></span><h3>7.4.6 Test image<a class="headerlink" href="#test-image" title="Link to this heading">#</a></h3>
<p>A <a class="reference internal" href="../3_glossary/3_Glossary.html#test-image"><span class="std std-ref"><strong>test image</strong></span></a> is an image taken from a camera after it has been set up to provide a permanent record of the <a class="reference internal" href="../3_glossary/3_Glossary.html#visit-metadata"><span class="std std-ref">visit metadata</span></a>. Taking a <a class="reference internal" href="../3_glossary/3_Glossary.html#test-image"><span class="std std-ref">test image</span></a> can be useful to compare the information from the <a class="reference internal" href="../3_glossary/3_Glossary.html#test-image"><span class="std std-ref">test image</span></a> to that which was collected on the <a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html#TOC_surv_guidelines_datasheet_service_retrieval"><span class="std std-ref">Camera Service/Retrieval Field Datasheet</span></a> after retrieval, which can help in reducing recording errors.</p>
<p>A <a class="reference internal" href="../3_glossary/3_Glossary.html#test-image"><span class="std std-ref"><strong>test image</strong></span></a> should include a <a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html#TOC_surv_guidelines_datasheet_test_image_sheet"><span class="std std-ref">Test Image Sheet</span></a> or whiteboard with information on the <a class="reference internal" href="../3_glossary/3_Glossary.html#sample-station-name"><span class="std std-ref">Sample Station Name</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">Camera Location Name</span></a>, Crew, and <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment-start-date-time"><span class="std std-ref">Deployment Start Date Time (DD-MMM-YYYY HH:MM:SS)</span></a>. See <a class="reference internal" href="1_10.1_AppendixA-Tables.html#TOC_surv_guidelines_table_a5"><span class="std std-ref">Appendix A - Table A5</span></a> for details on how to capture a <a class="reference internal" href="../3_glossary/3_Glossary.html#test-image"><span class="std std-ref">test image</span></a>, and for the provided <a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html#TOC_surv_guidelines_datasheet_test_image_sheet"><span class="std std-ref">Test Image Sheet</span></a>.</p>
</section>
<section id="deployment-area-photos-optional">
<span id="toc-surv-guidelines-deployment-area-photos"></span><h3>7.4.7 Deployment Area Photos (optional)<a class="headerlink" href="#deployment-area-photos-optional" title="Link to this heading">#</a></h3>
<p>It is useful to collect photos of the area around the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">camera location</span></a> (i.e., <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment-area-photos"><span class="std std-ref"><strong>deployment area photos</strong></span></a>) as a permanent, visual record of the <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Features</span></a>, <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location-characteristics"><span class="std std-ref">Camera Location Characteristics</span></a>, environmental conditions (e.g., vegetation, ecosite, or weather), or other variables of interest.</p>
<p>Take <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment-area-photos"><span class="std std-ref">deployment area photos</span></a> with a handheld digital camera or phone at each <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">camera location</span></a> at deployment, service and retrieval. The recommendation includes collecting four photos taken from the centre of the target detection zone (<a class="reference internal" href="#toc-surv-guidelines-fig-5"><span class="std std-ref">Figure 5</span></a>), facing each of the four cardinal directions. The documentation of the collection of these photos is recorded as “deployment area photos taken” (Y/N).</p>
<p>Record the image numbers (e.g., DSC100; “<a class="reference internal" href="../3_glossary/3_Glossary.html#deployment-area-photo-numbers"><span class="std std-ref">Deployment Area Photo Numbers</span></a>“) for each set of camera <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment-area-photos"><span class="std std-ref">deployment area photos</span></a> on a <a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html#FILES_surv_guidelines_datasheet_deployment"><span class="std std-ref">Camera Deployment Field Datasheet</span></a>).</p>
</section>
<section id="camera-location-characteristics">
<span id="toc-surv-guidelines-camera-location-characteristics"></span><h3>7.4.8 Camera Location Characteristics<a class="headerlink" href="#camera-location-characteristics" title="Link to this heading">#</a></h3>
<p><strong>Camera Location Characteristics</strong> are any significant features around the camera at the time of the visit. This may include for example, manmade or natural linear features (e.g., trails), habitat types (e.g., wetlands), wildlife structure (e.g., beaver dam). <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location-characteristics"><span class="std std-ref">Camera Location Characteristics</span></a> differ from <a class="reference internal" href="../3_glossary/3_Glossary.html#fov-target"><span class="std std-ref">FOV Target Features</span></a> in that <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location-characteristics"><span class="std std-ref">Camera Location Characteristics</span></a> could include those not in the camera’s Field of View.</p>
<p>Researchers typically record information about the environment at <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">camera locations</span></a> to better understand how this might affect animal occurrence or behaviour. It is recommended to record all <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location-characteristics"><span class="std std-ref">Camera Location Characteristics</span></a> and upload these to a digital data-collection platform with private or open settings like <a class="reference external" href="https://five.epicollect.net/">Epicollect</a>, using the template provided. Alternatively, you may choose to upload these photos using species identification models to an open-source platform like <a class="reference external" href="https://inaturalist.ca">inaturalist</a>, <a class="reference external" href="https://ualbertaca-my.sharepoint.com/personal/cjsteven_ualberta_ca/Documents/RCSC_RC-Survey-Guidelines_AB-Metadata-Standards/WildTrax">WildTrax</a> and/or <a class="reference external" href="https://www.alberta.ca/fisheries-and-wildlife-management-information-system-overview.aspx">FWMIS</a>.</p>
</section>
<section id="field-equipment">
<span id="toc-surv-guidelines-field-equipment"></span><h3>7.4.9 Field equipment<a class="headerlink" href="#field-equipment" title="Link to this heading">#</a></h3>
<p>Refer to <a class="reference internal" href="1_10.1_AppendixA-Tables.html#TOC_surv_guidelines_table_a4"><span class="std std-ref">Appendix A - Table A4</span></a> for a recommended list of field equipment for remote camera studies.</p>
</section>
</section>
<section id="metadata">
<span id="toc-surv-guidelines-metadata"></span><h2>7.5 Metadata<a class="headerlink" href="#metadata" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="../3_glossary/3_Glossary.html#metadata"><span class="std std-ref">Metadata</span></a> (i.e., data that provides information about other data) is critical to any scientific study or monitoring program. It helps to ensure that data are consistent and accurate and facilitates data sharing across <a class="reference internal" href="../3_glossary/3_Glossary.html#project"><span class="std std-ref">projects</span></a>. Alberta and British Columbia have established <a class="reference internal" href="../3_glossary/3_Glossary.html#metadata"><span class="std std-ref">metadata</span></a> standards (<a class="reference external" href="https://ab-rcsc.github.io/RCSC-WildCAM_Remote-Camera-Survey-Guidelines-and-Metadata-Standards/2_metadata-standards/2_0.1_Citation-and-Info.html">AB Metadata Standards</a> [RCSC, 2024] and the <a class="reference external" href="https://www2.gov.bc.ca/assets/gov/environment/natural-resource-stewardship/nr-laws-policy/risc/wcmp_v1.pdf">B.C. Metadata Standards</a> [RISC, 2019]) that all camera <a class="reference internal" href="../3_glossary/3_Glossary.html#project"><span class="std std-ref">projects</span></a> in the provinces should follow. In these guidelines, we focus on the metadata fields that pertain to the deployment of cameras, which should be collected when the user “visits” the location.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These guidelines do not describe all fields relevant to/required by the <a class="reference external" href="https://ab-rcsc.github.io/RCSC-WildCAM_Remote-Camera-Survey-Guidelines-and-Metadata-Standards/2_metadata-standards/2_0.1_Citation-and-Info.html">AB Metadata Standards</a> (RCSC, 2024) and <a class="reference external" href="https://www2.gov.bc.ca/assets/gov/environment/natural-resource-stewardship/nr-laws-policy/risc/wcmp_v1.pdf">B.C. Metadata Standards</a> (RISC, 2019). Similarly, there may be additional/alternative fields required by the Alberta Government’s <a class="reference external" href="https://www.alberta.ca/wildlife-loadforms.aspx">FWMIS loadform</a> (<a class="reference external" href="https://www.alberta.ca/wildlife-loadforms.aspx">https://www.alberta.ca/wildlife-loadforms.aspx</a>) for camera studies compared to those within these guidelines or the <a class="reference external" href="https://ab-rcsc.github.io/RCSC-WildCAM_Remote-Camera-Survey-Guidelines-and-Metadata-Standards/2_metadata-standards/2_0.1_Citation-and-Info.html">AB Metadata Standards</a> (RCSC, 2024). Every effort has been made to align the various sources where possible.</p>
</div>
<section id="metadata-deployment-service-and-retrieval">
<span id="toc-surv-guidelines-metadata-deployment-service-retrieval"></span><h3>7.5.1 Metadata - Deployment, Service and Retrieval<a class="headerlink" href="#metadata-deployment-service-and-retrieval" title="Link to this heading">#</a></h3>
<p>A <strong>visit</strong> is when a <a class="reference internal" href="../3_glossary/3_Glossary.html#crew"><span class="std std-ref">crew</span></a> has gone to a location to deploy (“<a class="reference internal" href="../3_glossary/3_Glossary.html#deployment-visit"><span class="std std-ref">deployment visit</span></a>“), service, or retrieve (“<a class="reference internal" href="../3_glossary/3_Glossary.html#service-retrieval-visit"><span class="std std-ref">service/retrieval visit</span></a>“) a remote camera.</p>
<p>A “<strong>deployment visit</strong>” is when a <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment-crew"><span class="std std-ref">Deployment Crew</span></a> has gone to a location to deploy a remote camera. Relevant <a class="reference internal" href="../3_glossary/3_Glossary.html#metadata"><span class="std std-ref">metadata</span></a> should be recorded when a camera is initially set up (deployed) using the <a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html#FILES_surv_guidelines_datasheet_deployment"><span class="std std-ref">Camera Deployment Field Datasheet</span></a>). Each event should have its own <a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html#FILES_surv_guidelines_datasheet_deployment"><span class="std std-ref">Camera Deployment Field Datasheet</span></a>).</p>
<p>If a camera is deployed for more than one <a class="reference internal" href="../3_glossary/3_Glossary.html#survey"><span class="std std-ref">survey</span></a>, the field <a class="reference internal" href="../3_glossary/3_Glossary.html#crew"><span class="std std-ref">crew</span></a>s will need to revisit the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">camera location</span></a> to “<strong>service</strong>” the camera and/or equipment (“<a class="reference internal" href="../3_glossary/3_Glossary.html#service-retrieval-crew"><span class="std std-ref">Service/Retrieval Crew</span></a>“; e.g., to refresh batteries or swap out SD cards. If the <a class="reference internal" href="../3_glossary/3_Glossary.html#service-retrieval-crew"><span class="std std-ref">Service/Retrieval Crew</span></a> visits the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">camera location</span></a> to collect the camera and other equipment (i.e., the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">camera location</span></a> will no longer be used and cameras, SD cards, and batteries are not replaced), this is referred to as a “<strong>retrieval</strong>” (i.e., the <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">camera location</span></a> will no longer be used, and the camera, SD card, and batteries are not replaced).</p>
<p>Whether the <a class="reference internal" href="../3_glossary/3_Glossary.html#crew"><span class="std std-ref">crew</span></a> services or retrieves the camera, relevant <a class="reference internal" href="../3_glossary/3_Glossary.html#service-retrieval-metadata"><span class="std std-ref">Service/Retrieval metadata</span></a> should be collected if there have been any changes to <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">camera location</span></a>, sampling period, and/or setting type (e.g., not <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">baited</span></a> and then <a class="reference internal" href="../3_glossary/3_Glossary.html#baitlure-bait"><span class="std std-ref">baited</span></a> later) using the <a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html#datasheet_service_retrieval"><span class="std std-ref">Camera Service/Retrieval Field Datasheet</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Note:</strong> the list of <a class="reference internal" href="../3_glossary/3_Glossary.html#service-retrieval-metadata"><span class="std std-ref">Service/Retrieval metadata</span></a> include additional <a class="reference internal" href="../3_glossary/3_Glossary.html#metadata"><span class="std std-ref">metadata</span></a> fields that are not included in the list of <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment-metadata"><span class="std std-ref">deployment metadata</span></a>.</p>
</div>
<p>Nested under the deployment level of the hierarchy, there are a few “groups” of information that help to comprehend the field metadata; these include:</p>
<ul class="simple">
<li><p>Visit Metadata (collected at deployment and service/retrieval)</p></li>
<li><p>Equipment Information (collected at both deployment and service/retrieval; fields vary by visit type)</p></li>
<li><p>Camera Settings (collected at deployment)</p></li>
<li><p>Camera Placement (collected at deployment)</p></li>
<li><p>Site Characteristics (collected at deployment)</p></li>
<li><p>Equipment Checks (collected at both deployment and service/retrieval)</p></li>
<li><p>Image Set Information (collected as a combination of information from deployment and service/retrieval visits metadata)</p></li>
</ul>
<p>Refer to <a class="reference internal" href="1_10.1_AppendixA-Tables.html#TOC_surv_guidelines_table_a5"><span class="std std-ref">Appendix A - Table A5</span></a> for a detailed step-by-step and full lists of metadata fields and to the <a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html#FILES_surv_guidelines_datasheet_deployment"><span class="std std-ref">Camera Deployment Field Datasheet</span></a>), and the <a class="reference internal" href="1_10.2_AppendixA-Field-Datasheets.html#datasheet_service_retrieval"><span class="std std-ref">Camera Service/Retrieval Field Datasheet</span></a>.</p>
</section>
<section id="spatial-information">
<span id="toc-surv-guidelines-metadata-spatial-information"></span><h3>7.5.2 Spatial information<a class="headerlink" href="#spatial-information" title="Link to this heading">#</a></h3>
<p>Coordinates collected in the field are often used to obtain land cover information via GIS and can be imperative to finding <a class="reference internal" href="../3_glossary/3_Glossary.html#camera-location"><span class="std std-ref">camera locations</span></a> later. A large margin of error in collecting coordinates may result in the misclassification of land cover (Robinson et al., 2020) or increase the difficulty of another field <a class="reference internal" href="../3_glossary/3_Glossary.html#crew"><span class="std std-ref">crew</span></a> finding a camera. It is important to record the accuracy (margin of error) of the GPS unit used to record spatial information (coordinates) (i.e., the <a class="reference internal" href="../3_glossary/3_Glossary.html#gps-unit-accuracy"><span class="std std-ref">GPS unit accuracy</span></a>, e.g., Garmin GPS devices are accurate to within +/- 15 metres 95% of the time). <a class="reference internal" href="../3_glossary/3_Glossary.html#gps-unit-accuracy"><span class="std std-ref">GPS unit accuracy</span></a> may vary by the make and model of the GPS unit (Hall et al., 2008), but it also may be affected by nearby vegetation, infrastructure, atmospheric interference, etc. (Ganskopp &amp; Johnson, 2007).</p>
</section>
<section id="sd-card-retrieval">
<span id="toc-surv-guidelines-metadata-sd-card-retrieval"></span><h3>7.5.3 SD card retrieval<a class="headerlink" href="#sd-card-retrieval" title="Link to this heading">#</a></h3>
<p>When retrieving camera SD cards, remove the SD card from the camera and place it into a SD card case, a 2.25” x 3.5”-coin envelope, or a similar pouch labelled with the <a class="reference internal" href="../3_glossary/3_Glossary.html#deployment-name"><span class="std std-ref">Deployment Name</span></a> and SD card number. If certain camera units are part of a larger <a class="reference internal" href="../3_glossary/3_Glossary.html#survey"><span class="std std-ref">survey</span></a> area, group these pouches into a larger envelope and mark it with the <a class="reference internal" href="../3_glossary/3_Glossary.html#project-name"><span class="std std-ref">Project Name</span></a>/<a class="reference internal" href="../3_glossary/3_Glossary.html#survey-name"><span class="std std-ref">Survey Name</span></a>.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./1_survey-guidelines"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1_6.0_Study-design.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">6.0 Study design</p>
      </div>
    </a>
    <a class="right-next"
       href="1_8.0_Data-management-and-processing.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">8.0 Data management and processing</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-hardware-options">7.1 Camera hardware options</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#battery-type">7.1.1 Battery type</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sd-cards">7.1.2 SD cards</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-settings">7.2 Camera settings</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#photos-vs-video">7.2.1 Photos vs video</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trigger-mode-s-time-lapse-vs-motion-detector">7.2.2 Trigger Mode(s) - Time-lapse <em>vs.</em> motion detector</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trigger-sensitivity-photos-per-trigger-motion-image-interval-and-quiet-period">7.2.3 Trigger Sensitivity, Photos Per Trigger, Motion Image Interval and Quiet Period</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#attractants-vs-no-attractants">7.3 Attractants <em>vs.</em> no attractants</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-placement">7.4 Camera placement</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fov-target-feature">7.4.1 FOV Target Feature</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-height">7.4.2 Camera Height</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-angle">7.4.3 Camera angle</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-direction">7.4.4 Camera Direction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#field-of-view-fov-and-walktest">7.4.5 Field of View (FOV) and Walktest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-image">7.4.6 Test image</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deployment-area-photos-optional">7.4.7 Deployment Area Photos (optional)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera-location-characteristics">7.4.8 Camera Location Characteristics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#field-equipment">7.4.9 Field equipment</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata">7.5 Metadata</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-deployment-service-and-retrieval">7.5.1 Metadata - Deployment, Service and Retrieval</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spatial-information">7.5.2 Spatial information</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sd-card-retrieval">7.5.3 SD card retrieval</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC), Stevenson, C., Hubbs, A., & Wildlife Cameras for Adaptive Management (WildCAM)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>