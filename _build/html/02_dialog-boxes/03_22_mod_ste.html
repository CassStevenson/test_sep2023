
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Space-to-event (STE) &#8212; Remote Camera Decision Support Tool - Concept Library</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy.css?v=7a364cf7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=cf5192f4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/03_22_mod_ste';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="space-to-event-ste">
<span id="i-mod-ste"></span><h1>Space-to-event (STE)<a class="headerlink" href="#space-to-event-ste" title="Link to this heading">#</a></h1>
<p><strong>Space-to-event (STE) model (Moeller et al., 2018)</strong>: A method used to estimate abundance or <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> that accounts for variable detection probability through the use of time-lapse images and is unaffected by animal movement rates (collapses sampling intervals to an instant in time, and thus estimates are unaffected by animal movement rates) (Moeller et al., 2018).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Assumptions, Pros, Cons</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Assumptions</div>
<ul class="simple">
<li><p class="sd-card-text">Demographic closure (i.e., no births or deaths) (Moeller et al., 2018)</p></li>
<li><p class="sd-card-text">Geographic closure (i.e., no immigration or emigration) (Moeller et al., 2018)</p></li>
<li><p class="sd-card-text">Camera locations are randomly placed (Moeller et al., 2018)</p></li>
<li><p class="sd-card-text">Detections are <a class="reference internal" href="09_glossary.html#independent-detections"><span class="std std-ref">independent</span></a> (Moeller et al., 2018)</p></li>
<li><p class="sd-card-text">Spatial counts of animals in a small area (or counts in equal subsets of the landscape) are Poisson-distributed (Loonam et al., 2021)</p></li>
<li><p class="sd-card-text">Detection is perfect (detection probability ‚Äò<em>p</em>‚Äô = 1) (Moeller et al., 2018)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Pros</div>
<ul class="simple">
<li><p class="sd-card-text">Can be efficient for estimating abundance of common species (with a lot of images) (Moeller et al., 2018)</p></li>
<li><p class="sd-card-text">Does not require estimate of movement rate (Moeller et al., 2018)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Cons</div>
<ul class="simple">
<li><p class="sd-card-text">Assumes that detection probability is 1 (Moeller et al., 2018)</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</details><div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Overview</label><div class="sd-tab-content docutils">
<p>This section will be available soon! In the meantime, check out the information in the other tabs!</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/00_coming_soon.png"><img alt="../_images/00_coming_soon.png" src="../_images/00_coming_soon.png" style="width: 300px;" /></a>
</figure>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
Advanced</label><div class="sd-tab-content docutils">
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>This content was adapted from</strong>: The Density Handbook, ‚Äú<a class="reference external" href="https://www.researchgate.net/publication/368601884_Using_Camera_Traps_to_Estimate_Medium_and_Large_Mammal_Density_Comparison_of_Methods_and_Recommendations_for_Wildlife_Managers">Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</a>‚Äù (Clarke et al., 2024)</p>
</div>
<p>The space-to-event model (STE) is an extension of the time-to-event model (TTE; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/ 03_21_mod_tte.html"><span>Time-to-event</span></a>) that measures the area, instead of the time, sampled before an image of an animal is observed (Moeller et al., 2018). The conceptual underpinnings of the STE are the same as those of the TTE, with the exception that sampling occasions are collapsed into instantaneous samples using time-lapse images ‚Äì photographs taken at predetermined periods of the day or night (e.g., every hour, every day at noon), regardless of whether animals are within frame (Figure 12; ; Moeller et al., 2018). Because they are collapsed into instants in time, there is no need to break sampling occasions down into sampling periods ‚Äì and no need for measures of animal movement speed.</p>
<figure class="align-center">
<img alt="../_images/clarke_et_al_2023_fig12_clipped.png" src="../_images/clarke_et_al_2023_fig12_clipped.png" />
</figure>
<p><strong>Clarke et al. (2023) - Fig. 12</strong> One of many time-lapse images taken at a camera station at noon. Notice, the camera trap captures an image at a predetermined time (12:00), regardless of whether an animal is within frame.</p>
<p>The STE model is based on the simple logic that, as population density increases, the number of animal images captured by the cameras in a network increases, and thus the number of cameras that capture images increases ‚Äì so, at a moment in time, the number of cameras from which images need to be ‚Äúdrawn‚Äù until an image of an animal is picked decreases (Lukacs, 2021). To visualize how to model works: say an array of camera traps is deployed randomly across a study landscape, and set to take images every hour, on the hour (i.e., hourly sampling occasion). After image collection, for each occasion, images are ‚Äúdrawn‚Äù from cameras in random order, until an image of an animal is picked (Moeller et al., 2018). An example encounter history after 7 sampling occasions (e.g., 7 hours), for which the average viewshed area <em>ùëé</em> is 20 m<sup>2</sup>, might look like: {NA, 40 m<sup>2</sup>, NA, NA, 1180 m<sup>2</sup>, NA, 800 m<sup>2</sup>}, where 40 m<sup>2</sup> indicates that images from 2 cameras had to be drawn before observing an animal, 1180 m<sup>2</sup> indicates images from 59 cameras had to be drawn, and so on; and NA indicates no animal detections for that occasion. This encounter history ‚Äì which summarizes the space until detections ‚Äì can then be plugged into a modified TTE equation to produce a density estimate (Moeller et al., 2018).</p>
<p>As with the TTE, the average area of a camera viewshed is calculated using the equation:</p>
<figure class="align-center">
<img alt="../_images/clarke_et_al_2023_eqn_tte2_ste1.png" src="../_images/clarke_et_al_2023_eqn_tte2_ste1.png" />
</figure>
<p>where <em>ùëü</em> is detection distance and <em>ùúÉ</em> is the angle of the camera lens in degrees (Moeller et al., 2018). <em>ùëü</em> ‚Äì instead of being the maximum distance at which an animal can trigger a camera‚Äôs motion sensor, however, as it is for the TTE ‚Äì is simply the maximum distance at which an animal is identifiable, and is measured using landmarks as references (Gilbert et al., 2021; Moeller et al., 2018).</p>
<h2 class="rubric" id="simulations-and-field-experiments">Simulations and Field Experiments</h2>
<p>Random walk simulations show that the STE ‚Äì unlike the TTE ‚Äì is insensitive to movement speed (Moeller et al., 2018). This means that the model produces unbiased estimates of density, whether animals move slowly or quickly.
The STE has been field-tested on high-density ungulates and low-density carnivores in Idaho:</p>
<ul class="simple">
<li><p>In Idaho, the STE produced an estimate of elk density comparable to an aerial survey and the TTE (Moeller et al., 2018). The precision of STE and TTE estimates was similar in this system.</p></li>
<li><p>For wolves ‚Äì a low-density, social species ‚Äì the STE yielded densities close to those from a parallel DNA mark-recapture study (Ausband et al., 2022). STEderived results were less precise, however. Density was also significantly overestimated during one survey period (before data transformation) because of high detection rates at a single camera (Ausband et al., 2022). The researchers recommended bootstrapping (i.e., resampling a data set with replacement) to correct estimates when a camera collects too few or too many images.</p></li>
<li><p>The model performed comparatively poorly for low-density, solitary cougars; STE estimates were less precise and more variable than those from genetic markrecapture and the random encounter model (REM; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_17_mod_rem.html"><span>Random encounter model</span></a>; ). Small sample sizes (i.e., few occasions with images of cougars) contributed to the STE‚Äôs inconsistency (). It is worth noting, however, that genetic mark-recapture-based estimates were also fairly inconsistent, and density was not calculable during some surveys due to a lack of recaptures, despite considerable field effort (). The STE may therefore still be an efficient alternative to DNA markrecapture.</p></li>
</ul>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
Visual resources</label><div class="sd-tab-content docutils">
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Moeller &amp; Lukacs, 2022</div>
<figure class="align-default">
<img alt="../_images/moeller_lukacs_2022_fig1.png" class="img-grid" src="../_images/moeller_lukacs_2022_fig1.png" />
</figure>
<p class="sd-card-text"><strong>Moeller &amp; Lukacs (2022)</strong> The spaceNtime workflow for count data. The user will go through five major steps for STE, TTE, and IS analyses. If the user has presence/absence (0 and 1) data instead of count data, the IS analysis is not appropriate, and the IS pathway should be removed from the flowchart.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_tte2_ste1.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_tte2_ste1.png" />
</figure>
<p class="sd-card-text">The average area of a camera viewshed is calculated using [this] equation.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Moeller et al., 2018</div>
<figure class="align-default">
<img alt="../_images/moeller_et_al_2018_fig3.png" class="img-grid" src="../_images/moeller_et_al_2018_fig3.png" />
</figure>
<p class="sd-card-text"><strong>Moeller et al. (2018) - Fig. 3</strong> Conceptual diagram of the space to event (STE) model. The circular sectors represent three different cameras on two different occasions (a-b). On each occasion j = 1, 2,‚Ä¶, J, we randomly order the cameras i = 1, 2,‚Ä¶, M. If the first animal detection is in the nth camera, the observed STE S j is the sum of the areas of cameras 1, 2,. .. n. (a) On occasion j = 1, camera 1 contains at least one animal, so we record the space to first event S j=1 = a 1. (b) On occasion j = 2, cameras 2 and 3 both contain animals, but we use the first camera in the series. Therefore, we record the space to first event S j=1 = a 1 + a 2 .</p>
</div>
</div>
</div>
</div>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_fig12_clipped.png" class="img-grid" src="../_images/clarke_et_al_2023_fig12_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Clarke et al. (2023) - Fig. 12</strong> One of many time-lapse images taken at a camera station at noon. Notice, the camera trap captures an image at a predetermined time (12:00), regardless of whether an animal is within frame.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-3">
Analytical tools &amp; resources</label><div class="sd-tab-content docutils">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Type</p></th>
<th class="head text-left"><p>Name</p></th>
<th class="head text-left"><p>Note</p></th>
<th class="head text-left"><p>URL</p></th>
<th class="head text-left"><p>Reference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>R package</p></td>
<td class="text-left"><p>spaceNtime: an R package for estimating abundance of unmarked animals using camera-trap photographs</p></td>
<td class="text-left"><p>free and open-source R package designed to assist in the implementation of the STE and TTE models, along with the IS estimator</p></td>
<td class="text-left"><p>&lt;<a class="github reference external" href="https://github.com/annam21/spaceNtime;">annam21/spaceNtime</a><br><a class="reference external" href="https://link.springer.com/article/10.1007/s42991-021-00181-8">https://link.springer.com/article/10.1007/s42991-021-00181-8</a></p></td>
<td class="text-left"><p>Moeller, A. K.,&amp;  Lukacs, P. M. (2022) spaceNtime: an R package for estimating abundance of unmarked animals using camera-trap photographs. <em>Mammalian Biology, 102</em>, 581‚Äì590. <a class="reference external" href="https://doi.org/10.1007/s42991-021-00181-8">https://doi.org/10.1007/s42991-021-00181-8</a></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource2_type</p></td>
<td class="text-left"><p>resource2_name</p></td>
<td class="text-left"><p>resource2_note</p></td>
<td class="text-left"><p>resource2_url</p></td>
<td class="text-left"><p>ref_bib_resource2_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource3_type</p></td>
<td class="text-left"><p>resource3_name</p></td>
<td class="text-left"><p>resource3_note</p></td>
<td class="text-left"><p>resource3_url</p></td>
<td class="text-left"><p>ref_bib_resource3_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource4_type</p></td>
<td class="text-left"><p>resource4_name</p></td>
<td class="text-left"><p>resource4_note</p></td>
<td class="text-left"><p>resource4_url</p></td>
<td class="text-left"><p>ref_bib_resource4_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource5_type</p></td>
<td class="text-left"><p>resource5_name</p></td>
<td class="text-left"><p>resource5_note</p></td>
<td class="text-left"><p>resource5_url</p></td>
<td class="text-left"><p>ref_bib_resource5_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource6_type</p></td>
<td class="text-left"><p>resource6_name</p></td>
<td class="text-left"><p>resource6_note</p></td>
<td class="text-left"><p>resource6_url</p></td>
<td class="text-left"><p>ref_bib_resource6_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource7_type</p></td>
<td class="text-left"><p>resource7_name</p></td>
<td class="text-left"><p>resource7_note</p></td>
<td class="text-left"><p>resource7_url</p></td>
<td class="text-left"><p>ref_bib_resource7_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource8_type</p></td>
<td class="text-left"><p>resource8_name</p></td>
<td class="text-left"><p>resource8_note</p></td>
<td class="text-left"><p>resource8_url</p></td>
<td class="text-left"><p>ref_bib_resource8_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource9_type</p></td>
<td class="text-left"><p>resource9_name</p></td>
<td class="text-left"><p>resource9_note</p></td>
<td class="text-left"><p>resource9_url</p></td>
<td class="text-left"><p>ref_bib_resource9_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource10_type</p></td>
<td class="text-left"><p>resource10_name</p></td>
<td class="text-left"><p>resource10_note</p></td>
<td class="text-left"><p>resource10_url</p></td>
<td class="text-left"><p>ref_bib_resource10_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource11_type</p></td>
<td class="text-left"><p>resource11_name</p></td>
<td class="text-left"><p>resource11_note</p></td>
<td class="text-left"><p>resource11_url</p></td>
<td class="text-left"><p>ref_bib_resource11_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource12_type</p></td>
<td class="text-left"><p>resource12_name</p></td>
<td class="text-left"><p>resource12_note</p></td>
<td class="text-left"><p>resource12_url</p></td>
<td class="text-left"><p>ref_bib_resource12_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource13_type</p></td>
<td class="text-left"><p>resource13_name</p></td>
<td class="text-left"><p>resource13_note</p></td>
<td class="text-left"><p>resource13_url</p></td>
<td class="text-left"><p>ref_bib_resource13_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource14_type</p></td>
<td class="text-left"><p>resource14_name</p></td>
<td class="text-left"><p>resource14_note</p></td>
<td class="text-left"><p>resource14_url</p></td>
<td class="text-left"><p>ref_bib_resource14_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource15_type</p></td>
<td class="text-left"><p>resource15_name</p></td>
<td class="text-left"><p>resource15_note</p></td>
<td class="text-left"><p>resource15_url</p></td>
<td class="text-left"><p>ref_bib_resource15_ref_id</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-4">
References</label><div class="sd-tab-content docutils">
<p>Ausband, D. E., Lukacs, P. M., Hurley, M., Roberts, S., Strickfaden, K., &amp; Moeller,  A. K. (2022). Estimating Wolf Abundance from Cameras. <em>Ecosphere, 13</em>(2), e3933. <a class="reference external" href="https://doi.org/10.1002/ecs2.3933">https://doi.org/10.1002/ecs2.3933</a></p>
<p>Clarke, J., Bohm, H., Burton, C., Constantinou, A. (2023). <em>Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</em>. <a class="reference external" href="https://doi.org/10.13140/RG.2.2.18364.72320">https://doi.org/10.13140/RG.2.2.18364.72320</a></p>
<p>Gilbert, N. A., Clare, J. D. J., Stenglein, J. L., &amp; Zuckerberg, B. (2021). Abundance estimation of unmarked animals based on camera-trap data. <em>Conservation Biology, 35</em>(1), 88‚Äì100. Medline. <a class="reference external" href="https://doi.org/10.1111/cobi.13517">https://doi.org/10.1111/cobi.13517</a></p>
<p>Lukacs, P. M. (2021, Oct 26).<em>Animal Abundance from Camera Data:Pipe Dream to Main Stream.</em> Presented at the FCFC Seminar. <a class="reference external" href="https://umontana.zoom.us/rec/play/eY6_CAjDNUjCAfFrmRvJH8NtrL4J38I46T5idY4gO3i1YHqxBnDUrDeufvgAps-D-aFJFJ_F9AMuE6k.VjerQ5kRpa5HsybV">https://umontana.zoom.us/rec/play/eY6_CAjDNUjCAfFrmRvJH8NtrL4J38I46T5idY4gO3i1YHqxBnDUrDeufvgAps-D-aFJFJ_F9AMuE6k.VjerQ5kRpa5HsybV</a></p>
<p>Moeller, A. K., Lukacs, P. M., &amp; Horne, J. S. (2018). Three Novel Methods to Estimate Abundance of Unmarked Animals using Remote Cameras. <em>Ecosphere, 9</em>(8), Article e02331. <a class="reference external" href="https://doi.org/10.1002/ecs2.2331">https://doi.org/10.1002/ecs2.2331</a></p>
<p>Moeller, A. K.,&amp;  Lukacs, P. M. (2022) spaceNtime: an R package for estimating abundance of unmarked animals using camera-trap photographs. <em>Mammalian Biology, 102</em>, 581‚Äì590. <a class="reference external" href="https://doi.org/10.1007/s42991-021-00181-8">https://doi.org/10.1007/s42991-021-00181-8</a></p>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              
              
              
              
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>