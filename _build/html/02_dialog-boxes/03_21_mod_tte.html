
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Time-to-event (TTE) &#8212; Remote Camera Decision Support Tool - Concept Library</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy.css?v=7a364cf7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=cf5192f4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/03_21_mod_tte';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="time-to-event-tte">
<span id="i-mod-tte"></span><h1>Time-to-event (TTE)<a class="headerlink" href="#time-to-event-tte" title="Link to this heading">#</a></h1>
<p><strong>Time-to-event (TTE) model (Moeller et al., 2018)</strong>: A method used to estimate abundance or <a class="reference internal" href="09_glossary.html#density"><span class="std std-ref">density</span></a> from the detection rate while accounting for animal movement rates (Moeller et al., 2018). The TTE model assumes perfect detection (though there is a model extension to account for imperfect detection that requires further testing).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Assumptions, Pros, Cons</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Assumptions</div>
<ul class="simple">
<li><p class="sd-card-text">Demographic closure (i.e., no births or deaths) (Moeller et al., 2018; Loonam et al., 2021)</p></li>
<li><p class="sd-card-text">Geographic closure (i.e., no immigration or emigration) at the level of the sampling frame (area of interest); this assumption does not apply at the plot-level (area sampled by the camera) (Moeller et al., 2018; Loonam et al., 2021)</p></li>
<li><p class="sd-card-text">Animal movement and behaviour are unaffected by the cameras (Palencia et al., 2021)</p></li>
<li><p class="sd-card-text">Camera locations placement is random, systematic, or systematic random (Moeller et al., 2018)</p></li>
<li><p class="sd-card-text">Detections are <a class="reference internal" href="09_glossary.html#independent-detections"><span class="std std-ref">independent</span></a> (Moeller et al., 2018)</p></li>
<li><p class="sd-card-text">Spatial counts of animals (or counts in equal subsets of the landscape) are Poisson-distributed (Loonam et al., 2021)</p></li>
<li><p class="sd-card-text">Accurate estimate of movement speed (Loonam et al., 2021)</p></li>
<li><p class="sd-card-text">Detection is perfect (detection probability ‘<em>p</em>’ =  1) (Moeller et al., 2018)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Pros</div>
<ul class="simple">
<li><p class="sd-card-text">Can be efficient for estimating abundance of common species (with a lot of images) (Moeller et al., 2018)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Cons</div>
<ul class="simple">
<li><p class="sd-card-text">Requires independent estimates of movement rate (difficult to obtain without telemetry data) (Moeller et al., 2018)</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</details><div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Overview</label><div class="sd-tab-content docutils">
<p>This section will be available soon!</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/00_coming_soon.png"><img alt="../_images/00_coming_soon.png" src="../_images/00_coming_soon.png" style="width: 300px;" /></a>
</figure>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
Advanced</label><div class="sd-tab-content docutils">
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>This content was adapted from</strong>: The Density Handbook, “<a class="reference external" href="https://www.researchgate.net/publication/368601884_Using_Camera_Traps_to_Estimate_Medium_and_Large_Mammal_Density_Comparison_of_Methods_and_Recommendations_for_Wildlife_Managers">Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</a>” (Clarke et al., 2024)</p>
</div>
<p>Time-to-event (TTE) analysis is used in many disciplines to estimate the rate at which an event occurs, by repeatedly measuring the time that elapses before said event takes place (). A TTE model might be used in medicine, for example, to approximate time from diagnosis until remission or death (Clark et al., 2003). Moeller et al. (2018) developed an extension of the TTE framework to estimate animal density using camera trap data, where the “event” of interest is an animal detection, and the rate of interest is animals per viewshed area – density (). Their version capitalizes on the fact that, at a randomly deployed motion-triggered camera, the time it takes to capture an image of an animal is a function of animal movement speed, detection probability and population size (Jennelle et al., 2002, Moeller et al., 2018, Parsons et al., 2017). When movement speed is known and detection probability is perfect, population size can be estimated by measuring the time from an arbitrary starting point until an image of an animal is captured (Lukacs, 2021; Moeller et al., 2018).</p>
<p>The equation for camera data-based density estimation using TTE is:</p>
<figure class="align-center">
<img alt="../_images/clarke_et_al_2023_eqn_tte1.png" src="../_images/clarke_et_al_2023_eqn_tte1.png" />
</figure>
<p>where <em>𝜆</em> is the average number of animals in the viewshed, given the time until an animal is detected, and <em>𝑎</em> is the average viewshed area. <em>𝑎</em> is calculated using the equation:</p>
<figure class="align-center">
<img alt="../_images/clarke_et_al_2023_eqn_tte2_ste1.png" src="../_images/clarke_et_al_2023_eqn_tte2_ste1.png" />
</figure>
<p>where <em>𝑟</em> is the trigger distance (i.e., the maximum distance from which an animal can reliably trigger a camera’s motion sensor), and <em>𝜃</em> is the angle of the camera lens in degrees (Moeller et al., 2018).</p>
<p>To illustrate how <em>𝜆</em> is calculated, let’s take a simple example. We begin by dividing the total time cameras are active into sampling occasions, then sampling periods (Figure 10; Moeller et al., 2018). We might choose to define a sampling occasion as a day, and a sampling period as one of 24 one-hour intervals in a day (Moeller et al., 2018). The images collected at a camera station can now be grouped by occasion and period to generate a detection history, and the number of sampling periods (i.e., <em>𝑘</em> out of 24) until an image of an animal is encountered can be determined for each sampling occasion (Moeller et al., 2018). The detection history at a given camera after 7 days might look something like {NA, NA, 7, NA, 22, 1, NA}, where NA indicates no animal detections for that day. Inputting this information into a likelihood equation generates the average number of animals in the viewshed, <em>𝜆</em> (Moeller et al., 2018).</p>
<figure class="align-center">
<img alt="../_images/clarke_et_al_2023_fig10_clipped.png" src="../_images/clarke_et_al_2023_fig10_clipped.png" />
</figure>
<p><strong>Clarke et al. (2023) - Fig. 10</strong> Adapted from Moeller et al. (2018). Visualization of how total sampling time at a camera station is broken down into sampling occasions and then sampling periods.</p>
<p>To account for movement, the sampling period is set as the average time animals take to pass through the camera viewshed (Moeller et al., 2018). Thus, practitioners need measures of animal movement speed.</p>
<h2 class="rubric" id="simulations-and-field-experiments">Simulations and Field Experiments</h2>
<p>Simulations show that:</p>
<ul class="simple">
<li><p>The TTE model tends to underestimate population density. In both walk () and random walk simulations (Moeller et al., 2018), the TTE yielded density estimates below the true value, whether populations were large or small, or animals moved quickly or slowly. Estimates were, however, particularly low for slow-moving species.</p></li>
<li><p>The TTE is sensitive to movement speed. Indeed, Loonam et al.’s (2021b) simulations showed that over- or underestimating movement rate biases density estimates. For example: a 50% underestimation of movement speed resulted in a density estimate 40% lower than the true density; overestimating movement speed by 200% resulted in density estimates that were over 85% higher than actual (). Taken together, these results suggest that the integrity of TTE estimates depends on the movement behaviour of the focal species, and obtaining accurate measures of animal movement speed.</p></li>
<li><p>The TTE model performs best when cameras are deployed randomly on the landscape. Setting cameras to maximize detections (i.e., targeted deployment) resulted in considerable over- or underestimates of density in walk simulations (). Of the sampling designs tested in Grosklos’ (in preparation) simulations, random camera placement produced the best results. Thus, practitioners using the TTE model are advised to deploy their camera networks randomly to minimize model bias.</p></li>
</ul>
<p>The TTE is robust to population openness and territoriality. Population openness is a violation of assumption 1 (population closure); territoriality is a violation of assumption 5 (animals are Poisson distributed across the landscape; Moeller et al., 2018). Neither appeared to impact TTE estimates – indicating that the model applies well to actual populations, which often violate these assumptions ().</p>
<p>It is worth noting that in all of Loonam et al.’s (2021b) simulations, the precision of TTE estimates was inflated – that is, estimates were calculated to be more precise than they actually were. Practitioners should keep this in mind when evaluating reported values of precision, as they may be artificially high.</p>
<p>In the field: the TTE has produced density estimates similar to established censusing techniques. Moeller et al., (2018) piloted the TTE on a population of elk in Idaho, and found that the model produced a density estimate comparable to an aerial survey of the same area – even though cameras were not deployed randomly. In this system, the TTE produced higher estimates of population density than either of its sister models (space-to-event (STE) and instantaneous sampling (IS); see below). For cougars – a low-density species – TTE-based estimates were actually more precise than both genetic mark-recapture and random encounter model (REM; see 2.2.3 Random Encounter Model) estimates, and similarly or more consistent across years, respectively (). Density estimates could have been biased and misleadingly precise, however, because of non-random camera placement (, Morin et al., 2022).</p>
<p>The TTE has also performed poorly in natural populations. A study on snowshoe hare found that the TTE tended to overestimate density compared with the REM and the random encounter and staying time model (REST; see 2.2.4 Random Encounter and Staying Time; Jensen et al., 2022). Out of the three camera-based models, the TTE was also the least consistent with live-trapping spatial capture-recapture (SCR; see 2.1.2 Spatial Capture-Recapture; Jensen et al., 2022).</p>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
Visual resources</label><div class="sd-tab-content docutils">
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_tte1.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_tte1.png" />
</figure>
<p class="sd-card-text"><strong>Clarke et al. (2023) - Eqn TTE</strong>:
The equation for camera data-based density estimation using TTE, where <em>𝜆</em> is the average number of animals in the viewshed, given the time until an animal is detected, and <em>𝑎</em> is the average viewshed area.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_tte2_ste1.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_tte2_ste1.png" />
</figure>
<p class="sd-card-text"><strong>Clarke et al. (2023) - Eqn TTE <em>𝑎</em></strong>:The equation for <em>𝑎</em> in camera data-based density estimation using TTE (refer to “Clarke et al. (2023)  - Eqn TTE”).</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_fig10_clipped.png" class="img-grid" src="../_images/clarke_et_al_2023_fig10_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Clarke et al. (2023) - Fig. 10</strong> Adapted from Moeller et al. (2018). Visualization of how total sampling time at a camera station is broken down into sampling occasions and then sampling periods.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_fig11_clipped.png" class="img-grid" src="../_images/clarke_et_al_2023_fig11_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Clarke et al. (2023) - Fig. 11</strong> Simple diagrams showing dispersed, clumped and Poisson-distributed animals (red dots) in space.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Moeller &amp; Lukacs, 2022</div>
<figure class="align-default">
<img alt="../_images/moeller_lukacs_2022_fig1.png" class="img-grid" src="../_images/moeller_lukacs_2022_fig1.png" />
</figure>
<p class="sd-card-text"><strong>Moeller &amp; Lukacs (2022)</strong> The spaceNtime workflow for count data. The user will go through five major steps for STE, TTE, and IS analyses. If the user has presence/absence (0 and 1) data instead of count data, the IS analysis is not appropriate, and the IS pathway should be removed from the flowchart.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
ref_intext_figure6_ref_id</div>
<figure class="align-default">
<img alt="../_images/figure6_filename.png" class="img-grid" src="../_images/figure6_filename.png" />
</figure>
<p class="sd-card-text">figure6_caption</p>
</div>
</div>
</div>
</div>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
ref_intext_vid1_ref_id</div>
<iframe 
    width="100%"
    height="300"
    src="vid1_url"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
</iframe>
<p class="sd-card-text">vid1_caption</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
ref_intext_vid2_ref_id</div>
<iframe 
    width="100%"
    height="300"
    src="vid2_url"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
</iframe>
<p class="sd-card-text">vid2_caption</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
ref_intext_vid3_ref_id</div>
<iframe 
    width="100%"
    height="300"
    src="vid3_url"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
</iframe>
<p class="sd-card-text">vid3_caption</p>
</div>
</div>
</div>
</div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-3">
Shiny apps/Widgets</label><div class="sd-tab-content docutils">
<p>Check back in the future!</p>
<div class="docutils">
</div>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-4">
Analytical tools &amp; resources</label><div class="sd-tab-content docutils">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Type</p></th>
<th class="head text-left"><p>Name</p></th>
<th class="head text-left"><p>Note</p></th>
<th class="head text-left"><p>URL</p></th>
<th class="head text-left"><p>Reference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>R package</p></td>
<td class="text-left"><p>spaceNtime: an R package for estimating abundance of unmarked animals using camera-trap photographs</p></td>
<td class="text-left"><p>free and open-source R package designed to assist in the implementation of the STE and TTE models, along with the IS estimator</p></td>
<td class="text-left"><p>&lt;<a class="github reference external" href="https://github.com/annam21/spaceNtime;">annam21/spaceNtime</a><br><a class="reference external" href="https://link.springer.com/article/10.1007/s42991-021-00181-8">https://link.springer.com/article/10.1007/s42991-021-00181-8</a></p></td>
<td class="text-left"><p>Moeller, A. K.,&amp;  Lukacs, P. M. (2022) spaceNtime: an R package for estimating abundance of unmarked animals using camera-trap photographs. <em>Mammalian Biology, 102</em>, 581–590. <a class="reference external" href="https://doi.org/10.1007/s42991-021-00181-8">https://doi.org/10.1007/s42991-021-00181-8</a></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-5">
References</label><div class="sd-tab-content docutils">
<p>Clark, T. G., Bradburn, M. J., Love, S. B., &amp; Altman, D. G. (2003). Survival Analysis Part I: Basic Concepts and First Analyses. <em>British Journal of Cancer, 89</em>(2), 232–38. <a class="reference external" href="https://doi.org/10.1038/sj.bjc.6601118">https://doi.org/10.1038/sj.bjc.6601118</a></p>
<p>Clarke, J., Bohm, H., Burton, C., Constantinou, A. (2023). <em>Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</em>. <a class="reference external" href="https://doi.org/10.13140/RG.2.2.18364.72320">https://doi.org/10.13140/RG.2.2.18364.72320</a></p>
<p>Jennelle et al., 2002</p>
<p>Jensen, P. O., Wirsing, A. J., &amp; Thornton, D. H. (2022). Using camera traps to estimate density of snowshoe hare ( Lepus americanus ): A keystone boreal forest herbivore. <em>Journal of Mammalogy, 103</em>(3), 693–710. <a class="reference external" href="https://doi.org/10.1093/jmammal/gyac009">https://doi.org/10.1093/jmammal/gyac009</a></p>
<p>(Lukacs, P. M. (2021, Oct 26).<em>Animal Abundance from Camera Data:Pipe Dream to Main Stream.</em> Presented at the FCFC Seminar. <a class="reference external" href="https://umontana.zoom.us/rec/play/eY6_CAjDNUjCAfFrmRvJH8NtrL4J38I46T5idY4gO3i1YHqxBnDUrDeufvgAps-D-aFJFJ_F9AMuE6k.VjerQ5kRpa5HsybV">https://umontana.zoom.us/rec/play/eY6_CAjDNUjCAfFrmRvJH8NtrL4J38I46T5idY4gO3i1YHqxBnDUrDeufvgAps-D-aFJFJ_F9AMuE6k.VjerQ5kRpa5HsybV</a></p>
<p>Moeller, A. K., Lukacs, P. M., &amp; Horne, J. S. (2018). Three Novel Methods to Estimate Abundance of Unmarked Animals using Remote Cameras. <em>Ecosphere, 9</em>(8), Article e02331. <a class="reference external" href="https://doi.org/10.1002/ecs2.2331">https://doi.org/10.1002/ecs2.2331</a></p>
<p>Moeller, A. K.,&amp;  Lukacs, P. M. (2022) spaceNtime: an R package for estimating abundance of unmarked animals using camera-trap photographs. <em>Mammalian Biology, 102</em>, 581–590. <a class="reference external" href="https://doi.org/10.1007/s42991-021-00181-8">https://doi.org/10.1007/s42991-021-00181-8</a></p>
<p>Morin, D. J., Boulanger, J., Bischof, R., Lee, D. C., Ngoprasert, D., Fuller, A. K., McLellan, B., Steinmetz, R., Sharma, S., Garshelis, D., Gopalaswamy, A., Nawaz, M. A., &amp; Karanth, U. (2022).comparison of methods for estimating Density and population trends for low-Density Asian bears. <em>Global Ecology and Conservation, 35</em>, e02058 <a class="reference external" href="https://doi.org/10.1016/j.gecco.2022.e02058">https://doi.org/10.1016/j.gecco.2022.e02058</a></p>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              
              
              
              
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>